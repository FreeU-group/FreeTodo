# éŸ³é¢‘æ¨¡å—è¯¦ç»†å®æ–½è®¡åˆ’

## ğŸ“‹ æ€»ä½“æ¶æ„

```
éŸ³é¢‘æ•è· â†’ å®æ—¶è¯†åˆ« â†’ æ–‡æœ¬ä¼˜åŒ– â†’ æ—¥ç¨‹æå– â†’ å­˜å‚¨ â†’ å›æ”¾
```

---

## é˜¶æ®µ1ï¼šéŸ³é¢‘æ•è·ï¼ˆå®Œå–„ä¼˜åŒ–ï¼‰

### 1.1 éº¦å…‹é£éŸ³é¢‘æ•è·ï¼ˆå¤–éƒ¨éŸ³é¢‘ï¼‰

#### å½“å‰å®ç°
- ä½¿ç”¨ `navigator.mediaDevices.getUserMedia` API
- åŸºæœ¬åŠŸèƒ½å¯ç”¨ï¼Œä½†éœ€è¦ä¼˜åŒ–

#### ä¼˜åŒ–æ–¹æ¡ˆ

**1.1.1 éŸ³é¢‘è´¨é‡ä¼˜åŒ–**
```typescript
// RecordingService.ts
const stream = await navigator.mediaDevices.getUserMedia({
  audio: {
    // åŸºç¡€è®¾ç½®
    echoCancellation: true,      // å›å£°æ¶ˆé™¤
    noiseSuppression: true,       // å™ªå£°æŠ‘åˆ¶
    autoGainControl: true,        // è‡ªåŠ¨å¢ç›Šæ§åˆ¶
    
    // é«˜çº§è®¾ç½®ï¼ˆå¦‚æœæµè§ˆå™¨æ”¯æŒï¼‰
    sampleRate: 48000,           // é‡‡æ ·ç‡ï¼š48kHzï¼ˆé«˜è´¨é‡ï¼‰
    channelCount: 1,              // å•å£°é“ï¼ˆè¯­éŸ³è¯†åˆ«è¶³å¤Ÿï¼‰
    sampleSize: 16,              // 16ä½é‡‡æ ·
    
    // å»¶è¿Ÿä¼˜åŒ–
    latency: 0.01,               // ä½å»¶è¿Ÿæ¨¡å¼ï¼ˆ10msï¼‰
    echoCancellationType: 'system', // ä½¿ç”¨ç³»ç»Ÿçº§å›å£°æ¶ˆé™¤
  }
});
```

**1.1.2 è®¾å¤‡é€‰æ‹©ä¼˜åŒ–**
```typescript
// è·å–å¯ç”¨éŸ³é¢‘è®¾å¤‡åˆ—è¡¨
const devices = await navigator.mediaDevices.enumerateDevices();
const audioInputs = devices.filter(device => device.kind === 'audioinput');

// è®©ç”¨æˆ·é€‰æ‹©è®¾å¤‡ï¼ˆæˆ–è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡ï¼‰
const selectedDeviceId = await selectBestAudioDevice(audioInputs);

// ä½¿ç”¨é€‰å®šçš„è®¾å¤‡
const stream = await navigator.mediaDevices.getUserMedia({
  audio: {
    deviceId: { exact: selectedDeviceId },
    // ... å…¶ä»–è®¾ç½®
  }
});
```

**1.1.3 é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶**
```typescript
async function getUserMediaWithRetry(maxRetries = 3): Promise<MediaStream> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: { /* ... */ }
      });
      
      // éªŒè¯æµæ˜¯å¦æœ‰æ•ˆ
      if (stream.getAudioTracks().length > 0) {
        return stream;
      }
      
      // å¦‚æœæ— æ•ˆï¼Œæ¸…ç†å¹¶é‡è¯•
      stream.getTracks().forEach(track => track.stop());
    } catch (error) {
      if (i === maxRetries - 1) {
        throw error;
      }
      
      // ç­‰å¾…åé‡è¯•
      await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
    }
  }
  
  throw new Error('æ— æ³•è·å–éŸ³é¢‘æµ');
}
```

**1.1.4 éŸ³é¢‘è´¨é‡ç›‘æ§**
```typescript
// ç›‘æ§éŸ³é¢‘è´¨é‡
function monitorAudioQuality(stream: MediaStream) {
  const audioTrack = stream.getAudioTracks()[0];
  const settings = audioTrack.getSettings();
  
  console.log('éŸ³é¢‘è®¾ç½®:', {
    sampleRate: settings.sampleRate,
    channelCount: settings.channelCount,
    echoCancellation: settings.echoCancellation,
    noiseSuppression: settings.noiseSuppression,
    autoGainControl: settings.autoGainControl,
  });
  
  // ç›‘å¬éŸ³é¢‘è½¨é“çŠ¶æ€
  audioTrack.addEventListener('ended', () => {
    console.warn('éŸ³é¢‘è½¨é“å·²ç»“æŸ');
  });
  
  audioTrack.addEventListener('mute', () => {
    console.warn('éŸ³é¢‘è½¨é“å·²é™éŸ³');
  });
  
  // ç›‘æ§éŸ³é¢‘ç”µå¹³ï¼ˆç”¨äºæ£€æµ‹æ˜¯å¦æœ‰å£°éŸ³ï¼‰
  const audioContext = new AudioContext();
  const analyser = audioContext.createAnalyser();
  const source = audioContext.createMediaStreamSource(stream);
  source.connect(analyser);
  
  const dataArray = new Uint8Array(analyser.frequencyBinCount);
  
  function checkAudioLevel() {
    analyser.getByteFrequencyData(dataArray);
    const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
    
    if (average < 10) {
      console.warn('éŸ³é¢‘ç”µå¹³è¿‡ä½ï¼Œå¯èƒ½æ²¡æœ‰å£°éŸ³è¾“å…¥');
    }
  }
  
  setInterval(checkAudioLevel, 1000);
}
```

#### å·¥å…·å’ŒAPI
- **Web API**: `navigator.mediaDevices.getUserMedia`
- **Web API**: `navigator.mediaDevices.enumerateDevices`
- **Web API**: `MediaStreamTrack.getSettings()`
- **Web API**: `AudioContext`, `AnalyserNode`

#### æµ‹è¯•è¦ç‚¹
1. âœ… ä¸åŒæµè§ˆå™¨çš„å…¼å®¹æ€§ï¼ˆChrome, Edge, Firefox, Safariï¼‰
2. âœ… ä¸åŒæ“ä½œç³»ç»Ÿçš„å…¼å®¹æ€§ï¼ˆWindows, macOS, Linuxï¼‰
3. âœ… ä¸åŒéŸ³é¢‘è®¾å¤‡çš„å…¼å®¹æ€§ï¼ˆå†…ç½®éº¦å…‹é£ã€å¤–æ¥éº¦å…‹é£ã€USBéº¦å…‹é£ï¼‰
4. âœ… éŸ³é¢‘è´¨é‡éªŒè¯ï¼ˆé‡‡æ ·ç‡ã€å£°é“æ•°ã€å»¶è¿Ÿï¼‰
5. âœ… é”™è¯¯å¤„ç†éªŒè¯ï¼ˆæƒé™æ‹’ç»ã€è®¾å¤‡ä¸å¯ç”¨ã€è®¾å¤‡æ–­å¼€ï¼‰

---

### 1.2 ç³»ç»ŸéŸ³é¢‘æ•è·

#### å½“å‰å®ç°
- ä½¿ç”¨ `navigator.mediaDevices.getDisplayMedia` API
- éœ€è¦ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©æ ‡ç­¾é¡µ

#### ä¼˜åŒ–æ–¹æ¡ˆ

**1.2.1 Electron ç¯å¢ƒä¼˜åŒ–**
```typescript
// ä½¿ç”¨ Electron desktopCapturer API
// preload.ts (å·²åœ¨ä¹‹å‰åˆ›å»º)
contextBridge.exposeInMainWorld('electronAPI', {
  getSystemAudioSources: async () => {
    return await ipcRenderer.invoke('get-system-audio-sources');
  },
  
  getSystemAudioStream: async (sourceId?: string) => {
    return await ipcRenderer.invoke('get-system-audio-stream', sourceId);
  },
});

// main.ts (å·²åœ¨ä¹‹å‰åˆ›å»º)
ipcMain.handle('get-system-audio-sources', async () => {
  const sources = await desktopCapturer.getSources({
    types: ['screen', 'window'],
  });
  
  return sources.map(source => ({
    id: source.id,
    name: source.name,
    display_id: source.display_id,
  }));
});
```

**1.2.2 æµè§ˆå™¨ç¯å¢ƒä¼˜åŒ–**
```typescript
// RecordingService.ts
async function getSystemAudioStream(): Promise<MediaStream> {
  // æ£€æŸ¥æ˜¯å¦åœ¨ Electron ç¯å¢ƒ
  const electronAPI = (window as any).electronAPI;
  
  if (electronAPI) {
    // Electron ç¯å¢ƒï¼šå°è¯•è‡ªåŠ¨é€‰æ‹©æº
    try {
      const sources = await electronAPI.getSystemAudioSources();
      if (sources.length > 0) {
        // è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªæºï¼ˆæˆ–è®©ç”¨æˆ·é€‰æ‹©ï¼‰
        const selectedSource = sources[0];
        console.log('è‡ªåŠ¨é€‰æ‹©éŸ³é¢‘æº:', selectedSource.name);
      }
    } catch (error) {
      console.warn('Electron API ä¸å¯ç”¨ï¼Œå›é€€åˆ°æ ‡å‡† API');
    }
  }
  
  // ä½¿ç”¨æ ‡å‡† getDisplayMedia API
  const stream = await navigator.mediaDevices.getDisplayMedia({
    audio: {
      echoCancellation: false,
      noiseSuppression: false,
      autoGainControl: false,
      // å°è¯•è¯·æ±‚ç³»ç»ŸéŸ³é¢‘ï¼ˆå¦‚æœæµè§ˆå™¨æ”¯æŒï¼‰
      suppressLocalAudioPlayback: false, // ä¸æŠ‘åˆ¶æœ¬åœ°éŸ³é¢‘æ’­æ”¾
    } as MediaTrackConstraints,
    video: {
      displaySurface: 'browser', // åªæ•è·æµè§ˆå™¨æ ‡ç­¾é¡µ
    },
  });
  
  // éªŒè¯æ˜¯å¦æœ‰éŸ³é¢‘è½¨é“
  if (stream.getAudioTracks().length === 0) {
    throw new Error('æ— æ³•è·å–ç³»ç»ŸéŸ³é¢‘ï¼Œè¯·ç¡®ä¿é€‰æ‹©äº†åŒ…å«éŸ³é¢‘çš„æ ‡ç­¾é¡µ');
  }
  
  // ç§»é™¤è§†é¢‘è½¨é“ï¼ˆæˆ‘ä»¬åªéœ€è¦éŸ³é¢‘ï¼‰
  stream.getVideoTracks().forEach(track => track.stop());
  
  return stream;
}
```

**1.2.3 ç”¨æˆ·ä½“éªŒä¼˜åŒ–**
```typescript
// æ˜¾ç¤ºå‹å¥½çš„æç¤º
function showSystemAudioPrompt() {
  // å¯ä»¥é€šè¿‡ UI ç»„ä»¶æ˜¾ç¤ºæç¤º
  return new Promise<boolean>((resolve) => {
    // æ˜¾ç¤ºæç¤ºå¯¹è¯æ¡†
    const confirmed = confirm(
      'éœ€è¦æ•è·ç³»ç»ŸéŸ³é¢‘ã€‚\n\n' +
      '1. ç‚¹å‡»"ç¡®å®š"åï¼Œæµè§ˆå™¨ä¼šå¼¹å‡ºé€‰æ‹©çª—å£\n' +
      '2. è¯·é€‰æ‹©è¦å…±äº«çš„æ ‡ç­¾é¡µï¼ˆåŒ…å«éŸ³é¢‘ï¼‰\n' +
      '3. ç¡®ä¿å‹¾é€‰"å…±äº«éŸ³é¢‘"é€‰é¡¹\n\n' +
      'æ˜¯å¦ç»§ç»­ï¼Ÿ'
    );
    
    resolve(confirmed);
  });
}

// åœ¨ RecordingService ä¸­ä½¿ç”¨
async start(): Promise<void> {
  if (this.audioSource === 'system') {
    const confirmed = await showSystemAudioPrompt();
    if (!confirmed) {
      throw new Error('ç”¨æˆ·å–æ¶ˆäº†ç³»ç»ŸéŸ³é¢‘æ•è·');
    }
    
    // ç»§ç»­è·å–éŸ³é¢‘æµ...
  }
}
```

**1.2.4 éŸ³é¢‘æºé€‰æ‹©UIï¼ˆå¯é€‰ï¼‰**
```typescript
// å¦‚æœæ˜¯åœ¨ Electron ç¯å¢ƒï¼Œå¯ä»¥æä¾›éŸ³é¢‘æºé€‰æ‹©UI
async function selectAudioSource(): Promise<string | null> {
  const electronAPI = (window as any).electronAPI;
  
  if (!electronAPI) {
    return null; // æµè§ˆå™¨ç¯å¢ƒï¼Œä½¿ç”¨é»˜è®¤æµç¨‹
  }
  
  const sources = await electronAPI.getSystemAudioSources();
  
  if (sources.length === 0) {
    return null;
  }
  
  if (sources.length === 1) {
    // åªæœ‰ä¸€ä¸ªæºï¼Œè‡ªåŠ¨é€‰æ‹©
    return sources[0].id;
  }
  
  // å¤šä¸ªæºï¼Œè®©ç”¨æˆ·é€‰æ‹©ï¼ˆå¯ä»¥é€šè¿‡ UI ç»„ä»¶å®ç°ï¼‰
  // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œè¿”å›ç¬¬ä¸€ä¸ª
  return sources[0].id;
}
```

#### å·¥å…·å’ŒAPI
- **Electron API**: `desktopCapturer.getSources()`
- **Web API**: `navigator.mediaDevices.getDisplayMedia`
- **Web API**: `MediaStreamTrack.getSettings()`

#### æµ‹è¯•è¦ç‚¹
1. âœ… Electron ç¯å¢ƒçš„å…¼å®¹æ€§
2. âœ… æµè§ˆå™¨ç¯å¢ƒçš„å…¼å®¹æ€§ï¼ˆChrome, Edgeï¼‰
3. âœ… ä¸åŒæ“ä½œç³»ç»Ÿçš„å…¼å®¹æ€§ï¼ˆWindows, macOS, Linuxï¼‰
4. âœ… éŸ³é¢‘æºé€‰æ‹©åŠŸèƒ½
5. âœ… é”™è¯¯å¤„ç†éªŒè¯ï¼ˆæƒé™æ‹’ç»ã€æºä¸å¯ç”¨ï¼‰

---

### 1.3 éŸ³é¢‘æµç®¡ç†

#### ç»Ÿä¸€éŸ³é¢‘æµå¤„ç†
```typescript
// RecordingService.ts
class RecordingService {
  private stream: MediaStream | null = null;
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  
  /**
   * è·å–éŸ³é¢‘æµï¼ˆç»Ÿä¸€å…¥å£ï¼‰
   */
  private async getAudioStream(): Promise<MediaStream> {
    if (this.audioSource === 'microphone') {
      return await this.getMicrophoneStream();
    } else {
      return await this.getSystemAudioStream();
    }
  }
  
  /**
   * éªŒè¯éŸ³é¢‘æµ
   */
  private validateStream(stream: MediaStream): void {
    if (stream.getAudioTracks().length === 0) {
      throw new Error('éŸ³é¢‘æµä¸­æ²¡æœ‰éŸ³é¢‘è½¨é“');
    }
    
    const audioTrack = stream.getAudioTracks()[0];
    const settings = audioTrack.getSettings();
    
    console.log('éŸ³é¢‘æµè®¾ç½®:', {
      sampleRate: settings.sampleRate,
      channelCount: settings.channelCount,
      deviceId: settings.deviceId,
    });
    
    // ç›‘å¬è½¨é“çŠ¶æ€
    audioTrack.addEventListener('ended', () => {
      console.warn('éŸ³é¢‘è½¨é“å·²ç»“æŸ');
      if (this.isRecording) {
        this.stop();
      }
    });
    
    audioTrack.addEventListener('mute', () => {
      console.warn('éŸ³é¢‘è½¨é“å·²é™éŸ³');
    });
  }
  
  /**
   * æ¸…ç†éŸ³é¢‘æµ
   */
  private cleanupStream(): void {
    if (this.stream) {
      this.stream.getTracks().forEach(track => {
        track.stop();
        this.stream!.removeTrack(track);
      });
      this.stream = null;
    }
    
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    
    this.analyser = null;
  }
}
```

---

## é˜¶æ®µ2ï¼šéŸ³é¢‘è½¬å½•è¯†åˆ«

### 2.1 å®æ—¶è¯†åˆ«æµç¨‹

#### å½“å‰å®ç°
- éº¦å…‹é£ï¼šWeb Speech API
- ç³»ç»ŸéŸ³é¢‘ï¼šFaster-Whisper (WebSocket)

#### ä¼˜åŒ–æ–¹æ¡ˆ

**2.1.1 éº¦å…‹é£è¯†åˆ«ï¼ˆWeb Speech APIï¼‰**
```typescript
// RecognitionService.ts
class RecognitionService {
  private recognition: SpeechRecognition | null = null;
  
  /**
   * åˆå§‹åŒ–è¯†åˆ«æœåŠ¡
   */
  private initializeRecognition(): void {
    const SpeechRecognition = (window as any).webkitSpeechRecognition || 
                             (window as any).SpeechRecognition;
    
    if (!SpeechRecognition) {
      throw new Error('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«');
    }
    
    this.recognition = new SpeechRecognition();
    
    // åŸºç¡€è®¾ç½®
    this.recognition.lang = 'zh-CN';              // ä¸­æ–‡
    this.recognition.continuous = true;           // è¿ç»­è¯†åˆ«
    this.recognition.interimResults = true;       // ä¸´æ—¶ç»“æœ
    
    // ä¼˜åŒ–è®¾ç½®
    this.recognition.maxAlternatives = 1;         // åªè¿”å›æœ€ä½³ç»“æœ
    this.recognition.serviceURI = '';             // ä½¿ç”¨é»˜è®¤æœåŠ¡
    
    // äº‹ä»¶ç›‘å¬
    this.recognition.onstart = () => {
      console.log('è¯­éŸ³è¯†åˆ«å·²å¼€å§‹');
      this.onStatusChange?.('running');
    };
    
    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      this.handleRecognitionResult(event);
    };
    
    this.recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      this.handleRecognitionError(event);
    };
    
    this.recognition.onend = () => {
      console.log('è¯­éŸ³è¯†åˆ«å·²ç»“æŸ');
      this.onStatusChange?.('idle');
      
      // å¦‚æœè¿˜åœ¨å½•éŸ³ï¼Œè‡ªåŠ¨é‡å¯è¯†åˆ«
      if (this.isRunning) {
        setTimeout(() => {
          this.recognition?.start();
        }, 100);
      }
    };
  }
  
  /**
   * å¤„ç†è¯†åˆ«ç»“æœ
   */
  private handleRecognitionResult(event: SpeechRecognitionEvent): void {
    let finalText = '';
    let interimText = '';
    
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const result = event.results[i];
      const text = result[0].transcript;
      
      if (result.isFinal) {
        finalText += text;
      } else {
        interimText += text;
      }
    }
    
    // è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆWeb Speech API ä¸ç›´æ¥æä¾›ï¼Œéœ€è¦ä¼°ç®—ï¼‰
    const now = Date.now();
    const startTime = (now - this.recognitionStartTime) / 1000;
    const endTime = startTime + (finalText.length / 4); // å‡è®¾4å­—/ç§’
    
    if (finalText) {
      this.onResult?.(finalText, true, startTime, endTime);
    }
    
    if (interimText) {
      this.onResult?.(interimText, false, startTime, endTime);
    }
  }
  
  /**
   * å¤„ç†è¯†åˆ«é”™è¯¯
   */
  private handleRecognitionError(event: SpeechRecognitionErrorEvent): void {
    const errorMap: Record<string, string> = {
      'no-speech': 'æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·è¯´è¯',
      'audio-capture': 'æ— æ³•æ•è·éŸ³é¢‘ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£',
      'network': 'ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥',
      'aborted': 'è¯†åˆ«å·²ä¸­æ­¢',
      'not-allowed': 'éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·å…è®¸éº¦å…‹é£æƒé™',
    };
    
    const errorMessage = errorMap[event.error] || `è¯†åˆ«é”™è¯¯: ${event.error}`;
    this.onError?.(new Error(errorMessage));
  }
}
```

**2.1.2 ç³»ç»ŸéŸ³é¢‘è¯†åˆ«ï¼ˆFaster-Whisper WebSocketï¼‰**
```typescript
// WebSocketRecognitionService.ts
class WebSocketRecognitionService {
  private ws: WebSocket | null = null;
  private audioContext: AudioContext | null = null;
  private scriptProcessor: ScriptProcessorNode | null = null;
  
  /**
   * åˆå§‹åŒ–éŸ³é¢‘å¤„ç†
   */
  private initializeAudioProcessing(stream: MediaStream): void {
    // åˆ›å»º AudioContextï¼Œé‡‡æ ·ç‡è®¾ä¸º 16kHzï¼ˆä¸åç«¯ä¸€è‡´ï¼‰
    this.audioContext = new AudioContext({
      sampleRate: 16000,
      latencyHint: 'interactive', // ä½å»¶è¿Ÿæ¨¡å¼
    });
    
    // åˆ›å»ºéŸ³é¢‘æº
    const source = this.audioContext.createMediaStreamSource(stream);
    
    // ä½¿ç”¨ ScriptProcessor è·å–åŸå§‹éŸ³é¢‘æ•°æ®
    // bufferSize: 4096 samples = 256ms @ 16kHz
    this.scriptProcessor = this.audioContext.createScriptProcessor(4096, 1, 1);
    
    this.scriptProcessor.onaudioprocess = (e) => {
      if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
        return;
      }
      
      const inputData = e.inputBuffer.getChannelData(0);
      
      // è½¬æ¢ä¸º Int16 PCMï¼ˆä¸åç«¯ä¸€è‡´ï¼‰
      const int16Array = new Int16Array(inputData.length);
      for (let i = 0; i < inputData.length; i++) {
        // å°† float32 (-1.0 åˆ° 1.0) è½¬æ¢ä¸º int16 (-32768 åˆ° 32767)
        const s = Math.max(-1, Math.min(1, inputData[i]));
        int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
      }
      
      // è®°å½•æ—¶é—´æˆ³ï¼ˆç”¨äºè®¡ç®—è¯†åˆ«ç»“æœçš„æ—¶é—´èŒƒå›´ï¼‰
      this.audioDataTimestamps.push({
        timestamp: Date.now(),
        samples: inputData.length,
      });
      
      // å‘é€ PCM æ•°æ®
      this.ws.send(int16Array.buffer);
    };
    
    source.connect(this.scriptProcessor);
    this.scriptProcessor.connect(this.audioContext.destination);
  }
  
  /**
   * å¤„ç† WebSocket æ¶ˆæ¯
   */
  private handleWebSocketMessage(event: MessageEvent): void {
    try {
      const data = JSON.parse(event.data);
      
      if (data.error) {
        this.onError?.(new Error(data.error));
        return;
      }
      
      if (data.text && this.onResult) {
        // è®¡ç®—æ—¶é—´èŒƒå›´
        const now = Date.now();
        const timeSinceStart = (now - this.recognitionStartTime) / 1000; // ç§’
        
        // æ ¹æ®åç«¯å¤„ç†çš„æ—¶é—´èŒƒå›´è®¡ç®—
        const processedDuration = this.chunkDuration; // 0.8ç§’
        const endTime = timeSinceStart;
        const startTime = Math.max(0, endTime - processedDuration);
        
        this.onResult(
          data.text,
          data.isFinal || false,
          startTime,
          endTime
        );
      }
    } catch (error) {
      console.error('å¤„ç† WebSocket æ¶ˆæ¯å¤±è´¥:', error);
      this.onError?.(error instanceof Error ? error : new Error('æœªçŸ¥é”™è¯¯'));
    }
  }
}
```

#### åç«¯ä¼˜åŒ–ï¼ˆFaster-Whisperï¼‰
```python
# voice_stream_whisper.py
class PCMAudioProcessor:
    def __init__(
        self,
        sample_rate: int = 16000,
        chunk_duration: float = 0.8,  # 0.8ç§’å¤„ç†ä¸€æ¬¡
        overlap: float = 0.3,         # 0.3ç§’é‡å 
        min_samples: int = 8000,      # æœ€å°0.5ç§’
    ):
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        self.overlap = overlap
        self.min_samples = min_samples
        
        # ç¼“å†²åŒº
        max_buffer_samples = int(sample_rate * 10.0)  # æœ€å¤š10ç§’
        max_buffer_size = max_buffer_samples * 2
        self.pcm_buffer = deque(maxlen=max_buffer_size)
        
        # å¤„ç†çŠ¶æ€
        self.is_processing = False
        self.last_process_time = time.time()
        self.recognition_start_time = time.time()  # è®°å½•è¯†åˆ«å¼€å§‹æ—¶é—´
    
    async def try_process(self) -> Optional[dict]:
        current_samples = len(self.pcm_buffer) // 2
        current_time = time.time()
        
        time_since_last = current_time - self.last_process_time
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³å¤„ç†æ¡ä»¶
        should_process = (
            current_samples >= self.min_samples
            and time_since_last >= self.chunk_duration
        )
        
        if not should_process:
            return None
        
        # å¦‚æœæ­£åœ¨å¤„ç†ï¼Œæ£€æŸ¥æ˜¯å¦è¶…æ—¶
        if self.is_processing:
            if time_since_last > self.chunk_duration * 2:
                logger.warning('ä¸Šæ¬¡å¤„ç†å¯èƒ½å¡ä½ï¼Œå…è®¸æ–°å¤„ç†')
            else:
                return None
        
        self.is_processing = True
        process_start_time = time.time()
        
        try:
            # æå–å¤„ç†æ•°æ®
            pcm_bytes = bytes(self.pcm_buffer)
            processed_samples = len(pcm_bytes) // 2
            
            # è½¬æ¢ä¸º numpy æ•°ç»„
            audio_array = self._convert_pcm_to_numpy(pcm_bytes)
            if audio_array is None:
                return None
            
            # è¯†åˆ«
            result = await self._transcribe(audio_array)
            
            process_duration = time.time() - process_start_time
            
            if result:
                # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆç›¸å¯¹äºè¯†åˆ«å¼€å§‹æ—¶é—´ï¼‰
                relative_start_time = (current_time - self.recognition_start_time) - (processed_samples / self.sample_rate)
                relative_end_time = current_time - self.recognition_start_time
                
                # æ¸…ç†ç¼“å†²åŒºï¼ˆä¿ç•™é‡å éƒ¨åˆ†ï¼‰
                keep_samples = int(self.sample_rate * self.overlap)
                keep_bytes = keep_samples * 2
                remove_samples = max(0, processed_samples - keep_samples)
                remove_bytes = remove_samples * 2
                
                for _ in range(min(remove_bytes, len(self.pcm_buffer))):
                    if len(self.pcm_buffer) > 0:
                        self.pcm_buffer.popleft()
                
                self.last_process_time = current_time
                self.is_processing = False
                
                return {
                    'text': result,
                    'isFinal': True,
                    'startTime': relative_start_time,
                    'endTime': relative_end_time,
                }
            
            self.is_processing = False
            return None
            
        except Exception as e:
            logger.error(f'å¤„ç†éŸ³é¢‘å¤±è´¥: {e}', exc_info=True)
            self.is_processing = False
            return None
```

#### å·¥å…·å’ŒAPI
- **Web Speech API**: `webkitSpeechRecognition` / `SpeechRecognition`
- **WebSocket API**: `WebSocket`
- **Web Audio API**: `AudioContext`, `ScriptProcessorNode`
- **åç«¯**: Faster-Whisper (Python)

#### æµ‹è¯•è¦ç‚¹
1. âœ… è¯†åˆ«å»¶è¿Ÿæµ‹è¯•ï¼ˆç›®æ ‡ï¼š< 1ç§’ï¼‰
2. âœ… è¯†åˆ«å‡†ç¡®ç‡æµ‹è¯•
3. âœ… ä¸åŒè¯­è¨€çš„å…¼å®¹æ€§
4. âœ… ç½‘ç»œé”™è¯¯å¤„ç†
5. âœ… éŸ³é¢‘æµæ–­å¼€å¤„ç†

---

## é˜¶æ®µ3ï¼šå›æ”¾ä¸€è‡´æ€§ä¿è¯

### 3.1 æ—¶é—´æˆ³å¯¹é½

#### å®æ–½æ­¥éª¤

**3.1.1 è¯†åˆ«æœåŠ¡è®°å½•æ—¶é—´èŒƒå›´**
```typescript
// WebSocketRecognitionService.ts
private handleWebSocketMessage(event: MessageEvent): void {
  const data = JSON.parse(event.data);
  
  if (data.text && this.onResult) {
    // ä½¿ç”¨åç«¯è¿”å›çš„ç²¾ç¡®æ—¶é—´èŒƒå›´
    const startTime = data.startTime || 0;  // ç§’
    const endTime = data.endTime || 0;      // ç§’
    
    this.onResult(
      data.text,
      data.isFinal || false,
      startTime,
      endTime
    );
  }
}
```

**3.1.2 å‰ç«¯è®°å½•æ—¶é—´èŒƒå›´**
```typescript
// VoiceModulePanel.tsx
const handleRecognitionResult = (
  text: string,
  isFinal: boolean,
  startTime?: number,  // ç§’
  endTime?: number     // ç§’
) => {
  if (!text.trim() || !isFinal) return;
  
  const recordingStartTime = useAppStore.getState().recordingStartTime;
  if (!recordingStartTime || startTime === undefined || endTime === undefined) {
    return;
  }
  
  // è½¬æ¢ä¸ºæ¯«ç§’
  const audioStart = startTime * 1000;  // æ¯«ç§’
  const audioEnd = endTime * 1000;      // æ¯«ç§’
  
  // åˆ›å»ºè½¬å½•ç»“æœ
  const transcript: TranscriptSegment = {
    id: `transcript_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`,
    rawText: text,
    audioStart: audioStart,  // æ¯«ç§’
    audioEnd: audioEnd,      // æ¯«ç§’
    timestamp: new Date(recordingStartTime.getTime() + audioStart),
    // ... å…¶ä»–å­—æ®µ
  };
  
  // ä¿å­˜è½¬å½•ç»“æœ
  addTranscript(transcript);
  
  // å¼‚æ­¥æå–å¹¶å­˜å‚¨éŸ³é¢‘ç‰‡æ®µï¼ˆä½¿ç”¨ç›¸åŒçš„æ—¶é—´èŒƒå›´ï¼‰
  extractAndUploadAudioSegment(
    audioStart,      // ä½¿ç”¨è¯†åˆ«æœåŠ¡è®°å½•çš„æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    audioEnd,        // ä½¿ç”¨è¯†åˆ«æœåŠ¡è®°å½•çš„æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    recordingStartTime,
    new Date(recordingStartTime.getTime() + audioEnd),
    transcript.id    // å…³è”è¯†åˆ«ç»“æœID
  ).catch(error => {
    console.error('æå–éŸ³é¢‘ç‰‡æ®µå¤±è´¥:', error);
  });
};
```

**3.1.3 æå–éŸ³é¢‘ç‰‡æ®µï¼ˆä½¿ç”¨ç›¸åŒçš„æ—¶é—´èŒƒå›´ï¼‰**
```typescript
// RecordingService.ts
async extractAudioSegment(
  startTime: number,  // æ¯«ç§’
  endTime: number     // æ¯«ç§’
): Promise<Blob | null> {
  if (!this.fullRecordingChunks || this.fullRecordingChunks.length === 0) {
    console.warn('[extractAudioSegment] æ²¡æœ‰å®Œæ•´çš„å½•éŸ³æ•°æ®');
    return null;
  }
  
  // åˆå¹¶æ‰€æœ‰å½•éŸ³å—
  const fullBlob = new Blob(this.fullRecordingChunks, {
    type: this.getSupportedMimeType() || 'audio/webm'
  });
  
  // ä½¿ç”¨ Web Audio API è§£ç 
  const audioContext = new AudioContext();
  const arrayBuffer = await fullBlob.arrayBuffer();
  const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
  
  // è®¡ç®—æ ·æœ¬èŒƒå›´
  const sampleRate = audioBuffer.sampleRate;
  const startSample = Math.floor((startTime / 1000) * sampleRate);
  const endSample = Math.floor((endTime / 1000) * sampleRate);
  
  // éªŒè¯èŒƒå›´
  if (startSample < 0 || endSample > audioBuffer.length || startSample >= endSample) {
    console.error('[extractAudioSegment] æ—¶é—´èŒƒå›´æ— æ•ˆ:', {
      startTime,
      endTime,
      startSample,
      endSample,
      audioLength: audioBuffer.length
    });
    return null;
  }
  
  // æå–éŸ³é¢‘æ•°æ®
  const extractedLength = endSample - startSample;
  const extractedBuffer = audioContext.createBuffer(
    audioBuffer.numberOfChannels,
    extractedLength,
    sampleRate
  );
  
  for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
    const channelData = audioBuffer.getChannelData(channel);
    const extractedData = extractedBuffer.getChannelData(channel);
    extractedData.set(channelData.subarray(startSample, endSample));
  }
  
  // é‡æ–°ç¼–ç ä¸º WAV
  const wavBlob = await this.encodeAudioBufferToWav(extractedBuffer);
  
  // éªŒè¯æ—¶é•¿
  const expectedDuration = (endTime - startTime) / 1000; // ç§’
  const actualDuration = extractedBuffer.duration; // ç§’
  
  if (Math.abs(expectedDuration - actualDuration) > 0.1) {
    console.warn('[extractAudioSegment] éŸ³é¢‘æ—¶é•¿ä¸åŒ¹é…:', {
      expected: expectedDuration,
      actual: actualDuration,
      diff: Math.abs(expectedDuration - actualDuration)
    });
  }
  
  return wavBlob;
}
```

**3.1.4 å›æ”¾æ—¶ä½¿ç”¨å…³è”çš„éŸ³é¢‘æ–‡ä»¶**
```typescript
// VoiceModulePanel.tsx
const handleSegmentClick = async (
  startMs: number,
  endMs: number,
  transcriptId?: string
) => {
  if (isRecording || !recordingStartTime) return;
  
  // ä¼˜å…ˆä½¿ç”¨è¯†åˆ«ç»“æœå¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶
  if (transcriptId) {
    const transcript = transcripts.find(t => t.id === transcriptId);
    if (transcript && transcript.audioFileId && transcript.uploadStatus === 'uploaded') {
      try {
        const audioUrl = await persistenceServiceRef.current.getAudioUrl(
          transcript.audioFileId
        );
        if (audioUrl) {
          console.log(`[handleSegmentClick] æ’­æ”¾è¯†åˆ«ç»“æœå¯¹åº”çš„éŸ³é¢‘: ${transcriptId}`);
          await playAudioFromUrl(audioUrl, 0); // ä»å¤´å¼€å§‹æ’­æ”¾
          return;
        }
      } catch (error) {
        console.error(`[handleSegmentClick] è·å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥:`, error);
      }
    }
  }
  
  // å¦‚æœæ²¡æœ‰å…³è”çš„éŸ³é¢‘æ–‡ä»¶ï¼Œå›é€€åˆ°ä»å®Œæ•´å½•éŸ³ä¸­æå–
  // ...
};
```

#### å·¥å…·å’ŒAPI
- **Web Audio API**: `AudioContext`, `AudioBuffer`
- **Blob API**: `Blob`, `URL.createObjectURL`

#### æµ‹è¯•è¦ç‚¹
1. âœ… æ—¶é—´æˆ³å¯¹é½éªŒè¯ï¼ˆè¯†åˆ«æ—¶é—´ vs æå–æ—¶é—´ï¼‰
2. âœ… éŸ³é¢‘æ—¶é•¿éªŒè¯ï¼ˆé¢„æœŸæ—¶é•¿ vs å®é™…æ—¶é•¿ï¼‰
3. âœ… å›æ”¾å†…å®¹éªŒè¯ï¼ˆå›æ”¾çš„å†…å®¹æ˜¯å¦åŒ¹é…è¯†åˆ«ç»“æœï¼‰
4. âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•ï¼ˆå¼€å§‹ã€ç»“æŸã€é‡å ï¼‰

---

## é˜¶æ®µ4ï¼šåç»­åŠŸèƒ½

### 4.1 æ–‡æœ¬ä¼˜åŒ–ï¼ˆLLMï¼‰

#### å½“å‰å®ç°
- ä½¿ç”¨ DeepSeek API ä¼˜åŒ–æ–‡æœ¬

#### ä¼˜åŒ–æ–¹æ¡ˆ
- æ‰¹é‡å¤„ç†ä¼˜åŒ–
- é”™è¯¯é‡è¯•æœºåˆ¶
- è¶…æ—¶å¤„ç†

### 4.2 æ—¥ç¨‹æå–

#### å½“å‰å®ç°
- ä»ä¼˜åŒ–åçš„æ–‡æœ¬ä¸­æå–æ—¥ç¨‹

#### ä¼˜åŒ–æ–¹æ¡ˆ
- æ”¹è¿›æ—¶é—´è§£æ
- æ”¯æŒæ›´å¤šæ—¶é—´æ ¼å¼
- æ™ºèƒ½æ¨æ–­

### 4.3 å­˜å‚¨å’ŒæŒä¹…åŒ–

#### å½“å‰å®ç°
- éŸ³é¢‘æ–‡ä»¶å­˜å‚¨
- è½¬å½•æ–‡æœ¬å­˜å‚¨
- æ—¥ç¨‹å­˜å‚¨

#### ä¼˜åŒ–æ–¹æ¡ˆ
- æ•°æ®åº“é›†æˆ
- ç´¢å¼•ä¼˜åŒ–
- æŸ¥è¯¢ä¼˜åŒ–

---

## æµ‹è¯•å’ŒéªŒè¯è®¡åˆ’

### å•å…ƒæµ‹è¯•
- éŸ³é¢‘æ•è·æµ‹è¯•
- è¯†åˆ«æœåŠ¡æµ‹è¯•
- éŸ³é¢‘æå–æµ‹è¯•
- å›æ”¾æµ‹è¯•

### é›†æˆæµ‹è¯•
- ç«¯åˆ°ç«¯æµç¨‹æµ‹è¯•
- ä¸åŒç¯å¢ƒæµ‹è¯•
- æ€§èƒ½æµ‹è¯•

### å…¼å®¹æ€§æµ‹è¯•
- æµè§ˆå™¨å…¼å®¹æ€§
- æ“ä½œç³»ç»Ÿå…¼å®¹æ€§
- è®¾å¤‡å…¼å®¹æ€§

---

## å®æ–½æ—¶é—´è¡¨

### Week 1
- Day 1-2: éŸ³é¢‘æ•è·ä¼˜åŒ–
- Day 3-4: è¯†åˆ«æœåŠ¡ä¼˜åŒ–
- Day 5-7: å›æ”¾ä¸€è‡´æ€§ä¿è¯

### Week 2
- Day 1-3: æµ‹è¯•å’Œä¿®å¤
- Day 4-5: æ€§èƒ½ä¼˜åŒ–
- Day 6-7: æ–‡æ¡£å’Œéƒ¨ç½²

