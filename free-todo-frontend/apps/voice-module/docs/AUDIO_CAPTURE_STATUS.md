# 音频捕获模块状态总结

## ✅ 已完成功能

### 1. 麦克风音频捕获（外部音频）
- ✅ 使用 `getUserMedia` API 获取麦克风音频流
- ✅ 音频质量优化（回声消除、噪声抑制、自动增益控制）
- ✅ 设备选择功能（用户可以选择使用哪个麦克风）
- ✅ 错误处理和重试机制（最多3次重试）
- ✅ 音频质量监控（实时显示音频电平）
- ✅ 音频电平过低警告

### 2. 系统音频捕获
- ✅ 使用 `getDisplayMedia` API 获取系统音频
- ✅ Electron 环境支持（desktopCapturer API）
- ✅ 自动移除视频轨道（只保留音频）
- ✅ 监听音频轨道结束事件（用户停止共享时自动停止）
- ✅ 友好的错误提示

### 3. 音频流处理
- ✅ MediaRecorder 录制（每30秒自动分段）
- ✅ AudioContext + AnalyserNode（用于波形显示）
- ✅ 音频数据块收集和存储
- ✅ 支持 WebM/Opus 格式

---

## 📊 当前音频处理流程

```
┌─────────────────────────────────────────────────────────────┐
│  音频捕获层 (RecordingService)                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. 获取音频流                                              │
│     ├─ 麦克风: getUserMedia (48kHz, 单声道)                │
│     └─ 系统音频: getDisplayMedia (浏览器标签页音频)         │
│                                                             │
│  2. 音频流处理（双通道）                                    │
│     ├─ 通道A: MediaRecorder → 存储（30秒分段）             │
│     │   └─ 用于回放和持久化                                │
│     │                                                       │
│     └─ 通道B: AudioContext → 识别服务                      │
│         ├─ 麦克风: Web Speech API（浏览器内置）            │
│         └─ 系统音频: WebSocket → Faster-Whisper（后端）    │
│                                                             │
│  3. 音频质量监控                                            │
│     ├─ 实时音频电平显示（0-100%）                          │
│     ├─ 低电平警告（<5%持续3秒）                            │
│     └─ 设备状态监听（断开/静音检测）                        │
│                                                             │
└─────────────────────────────────────────────────────────────┘
         │                    │
         ▼                    ▼
┌─────────────────┐  ┌──────────────────────┐
│  MediaRecorder  │  │  识别服务             │
│  (存储通道)      │  │  (识别通道)           │
└─────────────────┘  └──────────────────────┘
         │                    │
         ▼                    ▼
┌─────────────────┐  ┌──────────────────────┐
│  30秒音频段      │  │  实时识别结果         │
│  (WebM格式)      │  │  (文本+时间戳)        │
└─────────────────┘  └──────────────────────┘
         │                    │
         └────────┬───────────┘
                  ▼
         ┌─────────────────┐
         │  关联和回放       │
         │  识别结果 → 音频段│
         └─────────────────┘
```

---

## 🔍 当前实现细节

### 音频捕获流程

1. **启动录音**
   ```typescript
   RecordingService.start()
   ├─ 根据 audioSource 选择 API
   │  ├─ 'microphone' → getUserMedia (带设备选择)
   │  └─ 'system' → getDisplayMedia
   ├─ 创建 AudioContext + AnalyserNode (波形显示)
   ├─ 创建 MediaRecorder (存储)
   └─ 启动识别服务
      ├─ 麦克风 → RecognitionService (Web Speech API)
      └─ 系统音频 → WebSocketRecognitionService (Faster-Whisper)
   ```

2. **音频数据处理**
   - **存储通道**: MediaRecorder 每1秒收集数据，每30秒自动分段
   - **识别通道**:
     - 麦克风: Web Speech API 直接处理（浏览器内置）
     - 系统音频: ScriptProcessor → PCM Int16 → WebSocket → 后端

3. **音频段存储**
   - 每30秒自动分段
   - 上传到后端存储
   - 识别结果关联到对应的音频段

---

## 💡 当前架构的优势

1. **双通道设计**
   - 存储通道：高质量录制（48kHz），用于回放
   - 识别通道：优化后的格式（16kHz），用于识别
   - 互不干扰，各自优化

2. **实时性**
   - Web Speech API: 延迟 < 1秒（麦克风）
   - Faster-Whisper: 延迟 < 1秒（系统音频，0.8秒处理间隔）

3. **回放一致性**
   - 识别结果直接关联到已保存的音频段
   - 不需要手动提取，避免时间误差

---

## ⚠️ 当前限制和问题

### 1. 双通道同步问题
- **问题**: MediaRecorder 和识别服务使用同一个流，但处理方式不同
- **影响**: 理论上应该同步，但实际可能有微小差异
- **现状**: 通过关联音频段解决，基本满足需求

### 2. ScriptProcessor 已废弃
- **问题**: `ScriptProcessorNode` 已被标记为废弃
- **影响**: 未来浏览器可能不支持
- **建议**: 迁移到 `AudioWorklet`（需要重构）

### 3. 系统音频限制
- **问题**: 浏览器要求用户手动选择标签页
- **影响**: 无法自动捕获所有系统音频
- **现状**: 这是浏览器安全限制，无法绕过

---

## 🚀 下一步建议

### 短期优化（1-2周）

1. **音频捕获优化**
   - ✅ 已完成：设备选择、音频质量监控
   - 🔄 待优化：错误恢复机制（设备断开后自动重连）

2. **识别服务优化**
   - ✅ 已完成：错误处理、时间戳优化
   - 🔄 待优化：识别结果去重、合并连续结果

3. **回放一致性**
   - ✅ 已完成：关联音频段
   - 🔄 待优化：精确的时间定位（在音频段中的偏移）

### 中期改进（1-2月）

1. **迁移到 AudioWorklet**
   - 替换废弃的 ScriptProcessor
   - 更好的性能和实时性
   - 支持更复杂的音频处理

2. **VAD（语音活动检测）**
   - 只在有语音时识别
   - 降低延迟和资源消耗
   - 提高识别准确率

3. **音频压缩和优化**
   - 自动压缩音频文件
   - 清理过期音频
   - 索引和快速检索

### 长期规划（3-6月）

1. **音色识别**
   - 区分不同说话人
   - 多人对话场景支持

2. **多语言支持**
   - 自动语言检测
   - 中英混合识别

3. **离线支持**
   - 本地模型识别
   - 完全离线工作

---

## 📝 进入下一部分的建议

### 当前状态评估

**音频捕获模块完成度: 85%**

✅ **已完成**:
- 麦克风和系统音频捕获
- 设备选择和监控
- 错误处理和重试
- 音频质量监控

🔄 **待完善**:
- 错误恢复机制
- AudioWorklet 迁移
- 更精确的时间同步

### 建议的下一步

**选项1: 继续优化音频捕获（推荐）**
- 实现错误恢复机制
- 改进设备断开处理
- 优化音频质量设置

**选项2: 进入识别服务优化**
- 识别结果去重和合并
- 改进时间戳精度
- 优化识别延迟

**选项3: 进入存储和持久化**
- 音频文件压缩
- 索引和检索
- 清理策略

**选项4: 进入UI/UX优化**
- 更好的状态反馈
- 错误提示优化
- 用户体验改进

---

## 🎯 我的建议

**建议先完成音频捕获的收尾工作**，然后进入识别服务优化：

1. **完成错误恢复机制**（1-2天）
   - 设备断开后自动重连
   - 网络错误恢复

2. **进入识别服务优化**（1周）
   - 识别结果去重
   - 时间戳精度改进
   - 识别延迟优化

3. **然后进入存储优化**（1周）
   - 音频压缩
   - 索引和检索

这样可以让整个流程更加稳定和可靠。
