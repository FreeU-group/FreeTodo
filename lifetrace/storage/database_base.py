"""æ•°æ®åº“åŸºç¡€ç®¡ç†å™¨ - è´Ÿè´£æ•°æ®åº“åˆå§‹åŒ–å’Œä¼šè¯ç®¡ç†

ä½¿ç”¨ SQLModel è¿›è¡Œæ•°æ®åº“ç®¡ç†ï¼Œè¿ç§»ç”± Alembic å¤„ç†ã€‚
"""

import os
from contextlib import contextmanager

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from sqlmodel import Session, SQLModel

from lifetrace.util.logging_config import get_logger
from lifetrace.util.path_utils import get_database_path
from lifetrace.util.utils import ensure_dir

logger = get_logger()


class DatabaseBase:
    """æ•°æ®åº“åŸºç¡€ç®¡ç†ç±» - å¤„ç†æ•°æ®åº“åˆå§‹åŒ–å’Œä¼šè¯ç®¡ç†"""

    def __init__(self):
        self.engine = None
        self.SessionLocal = None
        self._init_database()

    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            db_path = str(get_database_path())
            # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            db_exists = os.path.exists(db_path)

            # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
            ensure_dir(os.path.dirname(db_path))

            # åˆ›å»ºå¼•æ“
            self.engine = create_engine("sqlite:///" + db_path, echo=False, pool_pre_ping=True)

            # åˆ›å»ºä¼šè¯å·¥å‚ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
            self.SessionLocal = sessionmaker(bind=self.engine)

            # å¯¼å…¥æ‰€æœ‰æ¨¡å‹ä»¥ç¡®ä¿ metadata åŒ…å«æ‰€æœ‰è¡¨
            from lifetrace.storage import models  # noqa: F401

            # åˆ›å»ºè¡¨ï¼ˆä»…åœ¨æ–°æ•°æ®åº“æ—¶ï¼‰
            # å¯¹äºç°æœ‰æ•°æ®åº“ï¼Œä½¿ç”¨ Alembic è¿›è¡Œè¿ç§»
            if not db_exists:
                SQLModel.metadata.create_all(bind=self.engine)
                logger.info(f"æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {db_path}")
            else:
                # å¯¹äºç°æœ‰æ•°æ®åº“ï¼Œç¡®ä¿æ‰€æœ‰è¡¨éƒ½å­˜åœ¨ï¼ˆè‡ªåŠ¨åˆ›å»ºç¼ºå¤±çš„è¡¨ï¼‰
                try:
                    SQLModel.metadata.create_all(bind=self.engine)
                    logger.info(f"æ•°æ®åº“è¡¨æ£€æŸ¥å®Œæˆ: {db_path}")
                except Exception as e:
                    logger.warning(f"åˆ›å»ºæ•°æ®åº“è¡¨æ—¶å‡ºç°è­¦å‘Š: {e}")

            # æ€§èƒ½ä¼˜åŒ–ï¼šæ·»åŠ å…³é”®ç´¢å¼•
            self._create_performance_indexes()

        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _create_performance_indexes(self):
        """åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•"""
        try:
            with self.engine.connect() as conn:
                # è·å–ç°æœ‰ç´¢å¼•åˆ—è¡¨ï¼ˆåªè·å–ç´¢å¼•åç§°ï¼‰
                existing_indexes = [
                    row[0]
                    for row in conn.execute(
                        text(
                            "SELECT name FROM sqlite_master WHERE type='index' AND name IS NOT NULL"
                        )
                    ).fetchall()
                ]
                # å®šä¹‰éœ€è¦åˆ›å»ºçš„ç´¢å¼•
                indexes_to_create = [
                    (
                        "idx_ocr_results_screenshot_id",
                        "CREATE INDEX IF NOT EXISTS idx_ocr_results_screenshot_id ON ocr_results(screenshot_id)",
                    ),
                    (
                        "idx_screenshots_created_at",
                        "CREATE INDEX IF NOT EXISTS idx_screenshots_created_at ON screenshots(created_at)",
                    ),
                    (
                        "idx_screenshots_app_name",
                        "CREATE INDEX IF NOT EXISTS idx_screenshots_app_name ON screenshots(app_name)",
                    ),
                    (
                        "idx_screenshots_event_id",
                        "CREATE INDEX IF NOT EXISTS idx_screenshots_event_id ON screenshots(event_id)",
                    ),
                    (
                        "idx_todos_parent_todo_id",
                        "CREATE INDEX IF NOT EXISTS idx_todos_parent_todo_id ON todos(parent_todo_id)",
                    ),
                    (
                        "idx_todos_status",
                        "CREATE INDEX IF NOT EXISTS idx_todos_status ON todos(status)",
                    ),
                    (
                        "idx_todos_deleted_at",
                        "CREATE INDEX IF NOT EXISTS idx_todos_deleted_at ON todos(deleted_at)",
                    ),
                    (
                        "idx_todos_priority",
                        "CREATE INDEX IF NOT EXISTS idx_todos_priority ON todos(priority)",
                    ),
                    (
                        "idx_todos_order",
                        'CREATE INDEX IF NOT EXISTS idx_todos_order ON todos("order")',
                    ),
                    (
                        "idx_attachments_file_hash",
                        "CREATE INDEX IF NOT EXISTS idx_attachments_file_hash ON attachments(file_hash)",
                    ),
                    (
                        "idx_attachments_deleted_at",
                        "CREATE INDEX IF NOT EXISTS idx_attachments_deleted_at ON attachments(deleted_at)",
                    ),
                    (
                        "idx_todo_attachment_relations_todo_id",
                        "CREATE INDEX IF NOT EXISTS idx_todo_attachment_relations_todo_id ON todo_attachment_relations(todo_id)",
                    ),
                    (
                        "idx_todo_attachment_relations_attachment_id",
                        "CREATE INDEX IF NOT EXISTS idx_todo_attachment_relations_attachment_id ON todo_attachment_relations(attachment_id)",
                    ),
                    (
                        "idx_tags_tag_name_unique",
                        "CREATE UNIQUE INDEX IF NOT EXISTS idx_tags_tag_name_unique ON tags(tag_name)",
                    ),
                    (
                        "idx_tags_deleted_at",
                        "CREATE INDEX IF NOT EXISTS idx_tags_deleted_at ON tags(deleted_at)",
                    ),
                    (
                        "idx_todo_tag_relations_todo_id",
                        "CREATE INDEX IF NOT EXISTS idx_todo_tag_relations_todo_id ON todo_tag_relations(todo_id)",
                    ),
                    (
                        "idx_todo_tag_relations_tag_id",
                        "CREATE INDEX IF NOT EXISTS idx_todo_tag_relations_tag_id ON todo_tag_relations(tag_id)",
                    ),
                    (
                        "idx_journals_date",
                        "CREATE INDEX IF NOT EXISTS idx_journals_date ON journals(date)",
                    ),
                    (
                        "idx_journals_deleted_at",
                        "CREATE INDEX IF NOT EXISTS idx_journals_deleted_at ON journals(deleted_at)",
                    ),
                    (
                        "idx_journal_tag_relations_journal_id",
                        "CREATE INDEX IF NOT EXISTS idx_journal_tag_relations_journal_id ON journal_tag_relations(journal_id)",
                    ),
                    (
                        "idx_journal_tag_relations_tag_id",
                        "CREATE INDEX IF NOT EXISTS idx_journal_tag_relations_tag_id ON journal_tag_relations(tag_id)",
                    ),
                    (
                        "idx_activities_start_time",
                        "CREATE INDEX IF NOT EXISTS idx_activities_start_time ON activities(start_time)",
                    ),
                    (
                        "idx_activities_end_time",
                        "CREATE INDEX IF NOT EXISTS idx_activities_end_time ON activities(end_time)",
                    ),
                    (
                        "idx_activity_event_relations_activity_id",
                        "CREATE INDEX IF NOT EXISTS idx_activity_event_relations_activity_id ON activity_event_relations(activity_id)",
                    ),
                    (
                        "idx_activity_event_relations_event_id",
                        "CREATE INDEX IF NOT EXISTS idx_activity_event_relations_event_id ON activity_event_relations(event_id)",
                    ),
                    (
                        "idx_chats_session_id",
                        "CREATE INDEX IF NOT EXISTS idx_chats_session_id ON chats(session_id)",
                    ),
                    (
                        "idx_messages_chat_id",
                        "CREATE INDEX IF NOT EXISTS idx_messages_chat_id ON messages(chat_id)",
                    ),
                ]

                # åˆ›å»ºç´¢å¼•
                created_count = 0
                for index_name, create_sql in indexes_to_create:
                    if index_name not in existing_indexes:
                        conn.execute(text(create_sql))
                        created_count += 1
                        logger.info(f"å·²åˆ›å»ºæ€§èƒ½ç´¢å¼•: {index_name}")

                conn.commit()

                # åªåœ¨æœ‰ç´¢å¼•è¢«åˆ›å»ºæ—¶æ‰“å°å®Œæˆä¿¡æ¯
                if created_count > 0:
                    logger.info(f"æ€§èƒ½ç´¢å¼•æ£€æŸ¥å®Œæˆï¼Œåˆ›å»ºäº† {created_count} ä¸ªç´¢å¼•")

                # æ•°æ®åº“è¿ç§»ï¼šä¸º audio_recordings è¡¨æ·»åŠ  event_id åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                self._migrate_audio_recordings_table(conn)

        except Exception as e:
            logger.warning(f"åˆ›å»ºæ€§èƒ½ç´¢å¼•å¤±è´¥: {e}")
            raise

    def _migrate_audio_recordings_table(self, conn):
        """è¿ç§» audio_recordings è¡¨ï¼Œæ·»åŠ ç¼ºå¤±çš„åˆ—ï¼Œç§»é™¤ä¸éœ€è¦çš„åˆ—"""
        try:
            # æ£€æŸ¥ audio_recordings è¡¨æ˜¯å¦å­˜åœ¨
            table_exists = conn.execute(
                text(
                    "SELECT name FROM sqlite_master WHERE type='table' AND name='audio_recordings'"
                )
            ).fetchone()

            if not table_exists:
                # è¡¨ä¸å­˜åœ¨ï¼Œä¼šåœ¨åˆ›å»ºè¡¨æ—¶è‡ªåŠ¨åŒ…å«æ‰€æœ‰åˆ—
                return

            # è·å–ç°æœ‰åˆ—ä¿¡æ¯ï¼ˆåŒ…æ‹¬åˆ—åå’Œæ˜¯å¦å¯ç©ºï¼‰
            columns_info = conn.execute(text("PRAGMA table_info(audio_recordings)")).fetchall()
            # col[1] æ˜¯åˆ—å, col[3] æ˜¯ notnull (1=NOT NULL, 0=å¯ç©º)
            existing_columns = {col[1]: col[3] for col in columns_info}

            # æ£€æŸ¥æ˜¯å¦æœ‰ file_path åˆ—ï¼ˆæ—§ç‰ˆæœ¬é—ç•™ï¼Œåº”è¯¥ç§»é™¤ï¼Œå› ä¸ºæ–‡ä»¶è·¯å¾„å­˜å‚¨åœ¨ Attachment è¡¨ä¸­ï¼‰
            if "file_path" in existing_columns:
                # SQLite ä¸æ”¯æŒç›´æ¥åˆ é™¤åˆ—æˆ–ä¿®æ”¹åˆ—çº¦æŸï¼Œéœ€è¦é‡å»ºè¡¨
                logger.info(
                    "ğŸ”„ æ£€æµ‹åˆ° audio_recordings è¡¨ä¸­æœ‰ file_path åˆ—ï¼ˆæ—§ç‰ˆæœ¬é—ç•™ï¼‰ï¼Œå¼€å§‹è¿ç§»..."
                )
                try:
                    # è·å–æ‰€æœ‰åˆ—ä¿¡æ¯ï¼ˆç”¨äºæ„å»º SELECT è¯­å¥ï¼‰
                    columns_info_full = conn.execute(
                        text("PRAGMA table_info(audio_recordings)")
                    ).fetchall()

                    # æ„å»ºåˆ—ååˆ—è¡¨ï¼ˆæ’é™¤ file_pathï¼‰
                    col_names = [col[1] for col in columns_info_full if col[1] != "file_path"]
                    col_names_str = ", ".join(col_names)

                    # 1. åˆ›å»ºæ–°è¡¨å¹¶å¤åˆ¶æ•°æ®ï¼ˆæ’é™¤ file_path åˆ—ï¼‰
                    # æ³¨æ„ï¼šè¿™ç§æ–¹æ³•ä¼šä¸¢å¤±ä¸»é”®ã€ç´¢å¼•ç­‰ï¼Œä½†ä¼šä¿ç•™æ•°æ®
                    create_table_sql = f"""
                        CREATE TABLE audio_recordings_new AS
                        SELECT {col_names_str}
                        FROM audio_recordings
                    """
                    conn.execute(text(create_table_sql))

                    # 2. åˆ é™¤æ—§è¡¨
                    conn.execute(text("DROP TABLE audio_recordings"))

                    # 3. é‡å‘½åæ–°è¡¨
                    conn.execute(
                        text("ALTER TABLE audio_recordings_new RENAME TO audio_recordings")
                    )

                    # 4. é‡æ–°åˆ›å»ºä¸»é”®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    # æ£€æŸ¥åŸè¡¨æ˜¯å¦æœ‰ä¸»é”®
                    pk_columns = [
                        col[1] for col in columns_info_full if col[5] == 1
                    ]  # col[5] æ˜¯ pk
                    if pk_columns:
                        # SQLite ä¸æ”¯æŒç›´æ¥æ·»åŠ ä¸»é”®ï¼Œéœ€è¦å†æ¬¡é‡å»ºè¡¨
                        # ä½†ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶è·³è¿‡è¿™ä¸€æ­¥ï¼Œå› ä¸º id åˆ—é€šå¸¸ä¼šè‡ªåŠ¨æˆä¸ºä¸»é”®
                        # å¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤æ‚çš„é€»è¾‘
                        pass

                    logger.info("âœ… å·²æˆåŠŸç§»é™¤ audio_recordings è¡¨ä¸­çš„ file_path åˆ—")

                    # é‡æ–°è·å–åˆ—ä¿¡æ¯
                    columns_info = conn.execute(
                        text("PRAGMA table_info(audio_recordings)")
                    ).fetchall()
                    existing_columns = {col[1]: col[3] for col in columns_info}

                except Exception as e:
                    logger.warning(f"âš ï¸ è¿ç§» file_path åˆ—å¤±è´¥: {e}ï¼Œå°†å°è¯•æ·»åŠ ç¼ºå¤±çš„åˆ—")

            # éœ€è¦æ·»åŠ çš„åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰- æŒ‰ç…§æ¨¡å‹å®šä¹‰æ·»åŠ æ‰€æœ‰ç¼ºå¤±çš„åˆ—
            columns_to_add = [
                ("event_id", "INTEGER"),  # å…³è” Event
                ("attachment_id", "INTEGER"),  # å…³è” Attachmentï¼ˆéŸ³é¢‘æ–‡ä»¶ï¼‰
                ("duration_seconds", "INTEGER"),  # å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
                ("transcript_text", "TEXT"),  # åŸå§‹è½¬å½•æ–‡æœ¬
                ("optimized_text", "TEXT"),  # ä¼˜åŒ–åçš„æ–‡æœ¬
                ("summary_text", "TEXT"),  # æ‘˜è¦æ–‡æœ¬
                ("extracted_todos", "TEXT"),  # æå–çš„å¾…åŠäº‹é¡¹ï¼ˆJSONæ ¼å¼ï¼‰
                ("num_speakers", "INTEGER"),  # è¯´è¯äººæ•°é‡
                ("segment_id", "VARCHAR(200)"),  # å‰ç«¯segment ID
                ("title", "VARCHAR(500)"),  # å½•éŸ³æ ‡é¢˜
                (
                    "is_transcribed",
                    "INTEGER DEFAULT 0",
                ),  # æ˜¯å¦å·²é€šè¿‡å®Œæ•´éŸ³é¢‘è½¬å½•ï¼ˆSQLite ä½¿ç”¨ INTEGER è¡¨ç¤ºå¸ƒå°”å€¼ï¼‰
                ("is_extracted", "INTEGER DEFAULT 0"),  # æ˜¯å¦å·²æ™ºèƒ½æå–ï¼ˆå¾…åŠã€æ—¥ç¨‹ï¼‰
                ("is_summarized", "INTEGER DEFAULT 0"),  # æ˜¯å¦å·²ç”Ÿæˆæ™ºèƒ½çºªè¦
                ("is_full_audio", "INTEGER DEFAULT 0"),  # æ˜¯å¦ä¸ºå®Œæ•´éŸ³é¢‘ï¼ˆç”¨äºå›æ”¾ï¼‰
                ("is_segment_audio", "INTEGER DEFAULT 0"),  # æ˜¯å¦ä¸ºåˆ†æ®µéŸ³é¢‘ï¼ˆ10ç§’ï¼Œç”¨äºè½¬å½•ï¼‰
            ]

            for column_name, column_type in columns_to_add:
                if column_name not in existing_columns:
                    try:
                        alter_sql = (
                            f"ALTER TABLE audio_recordings ADD COLUMN {column_name} {column_type}"
                        )
                        conn.execute(text(alter_sql))
                        logger.info(f"âœ… å·²ä¸º audio_recordings è¡¨æ·»åŠ åˆ—: {column_name}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ·»åŠ åˆ— {column_name} å¤±è´¥: {e}")

            conn.commit()
        except Exception as e:
            logger.warning(f"è¿ç§» audio_recordings è¡¨å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç»§ç»­è¿è¡Œ

    @contextmanager
    def get_session(self):
        """è·å–æ•°æ®åº“ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆä½¿ç”¨ SQLModel Sessionï¼‰"""
        with Session(self.engine) as session:
            try:
                yield session
                session.commit()
            except Exception as e:
                session.rollback()
                logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
                raise

    @contextmanager
    def get_sqlalchemy_session(self):
        """è·å– SQLAlchemy ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆç”¨äºå…¼å®¹æ—§ä»£ç ï¼‰"""
        session = self.SessionLocal()
        try:
            yield session
            session.commit()
        except Exception as e:
            session.rollback()
            logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            raise
        finally:
            session.close()


# æ•°æ®åº“ä¼šè¯ç”Ÿæˆå™¨ï¼ˆç”¨äºä¾èµ–æ³¨å…¥ï¼‰
def get_db(db_base: DatabaseBase):
    """è·å–æ•°æ®åº“ä¼šè¯çš„ç”Ÿæˆå™¨å‡½æ•°"""
    session = db_base.SessionLocal()
    try:
        yield session
    finally:
        session.close()
