"""å®æ—¶è¯­éŸ³è¯†åˆ« WebSocket è·¯ç”± - ç›´æ¥å®ç° WhisperLiveKit æ ¸å¿ƒæŠ€æœ¯

ä¸ä¾èµ–ç‹¬ç«‹çš„ WhisperLiveKit æœåŠ¡å™¨ï¼Œç›´æ¥ä½¿ç”¨ Faster-Whisper + WhisperLiveKit ç®—æ³•
å®ç°è¶…ä½å»¶è¿Ÿå®æ—¶è½¬å½•ï¼ˆ< 300msï¼‰
"""

import asyncio
import json
from typing import Optional, Dict, Any, List
from collections import deque
import time
import numpy as np

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from lifetrace.util.logging_config import get_logger
from lifetrace.util.settings import settings

logger = get_logger()

router = APIRouter(prefix="/api/voice", tags=["voice-stream-whisperlivekit-native"])


def convert_traditional_to_simplified(text: str) -> str:
    """å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡"""
    try:
        import opencc
        converter = opencc.OpenCC('t2s')
        return converter.convert(text)
    except ImportError:
        return text


class IncrementalContext:
    """å¢é‡å¤„ç†ä¸Šä¸‹æ–‡ - ä¿æŒè¯­éŸ³ä¸Šä¸‹æ–‡ï¼Œé¿å…åˆ‡å‰²ï¼ˆå‚è€ƒ WhisperLiveKitï¼‰
    
    æ ¸å¿ƒæ€æƒ³ï¼šä¿æŒä¸€ä¸ªæ»‘åŠ¨çª—å£çš„ä¸Šä¸‹æ–‡ï¼Œæ¯æ¬¡å¤„ç†æ—¶åŒ…å«å‰é¢çš„ä¸Šä¸‹æ–‡ï¼Œ
    è¿™æ ·å¯ä»¥é¿å…åœ¨è¯ä¸­é—´åˆ‡å‰²ï¼Œä¿æŒè¯­ä¹‰è¿è´¯æ€§ã€‚
    """
    
    def __init__(self, context_duration: float = 1.0, sample_rate: int = 16000):
        self.context_duration = context_duration
        self.sample_rate = sample_rate
        self.max_context_samples = int(context_duration * sample_rate)
        self.context_buffer = deque(maxlen=self.max_context_samples)
        logger.debug(f"å¢é‡ä¸Šä¸‹æ–‡åˆå§‹åŒ–: context_duration={context_duration}s, max_samples={self.max_context_samples}")
    
    def add_audio(self, audio_array: np.ndarray):
        """æ·»åŠ éŸ³é¢‘åˆ°ä¸Šä¸‹æ–‡ç¼“å†²åŒº"""
        self.context_buffer.extend(audio_array)
    
    def get_context_audio(self, current_audio: np.ndarray) -> np.ndarray:
        """è·å–å¸¦ä¸Šä¸‹æ–‡çš„éŸ³é¢‘ï¼ˆç”¨äºè¯†åˆ«ï¼‰"""
        context = np.array(list(self.context_buffer))
        if len(context) > 0:
            # æ‹¼æ¥ä¸Šä¸‹æ–‡å’Œå½“å‰éŸ³é¢‘
            combined = np.concatenate([context, current_audio])
            # æ›´æ–°ä¸Šä¸‹æ–‡ï¼ˆä¿ç•™éƒ¨åˆ†å½“å‰éŸ³é¢‘ä½œä¸ºä¸‹æ¬¡çš„ä¸Šä¸‹æ–‡ï¼‰
            overlap_samples = min(len(current_audio), self.max_context_samples // 2)
            self.context_buffer.clear()
            self.context_buffer.extend(current_audio[-overlap_samples:])
            return combined
        else:
            # æ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œç›´æ¥ä½¿ç”¨å½“å‰éŸ³é¢‘
            overlap_samples = min(len(current_audio), self.max_context_samples // 2)
            self.context_buffer.extend(current_audio[-overlap_samples:])
            return current_audio


class ImprovedVAD:
    """æ”¹è¿›çš„ VADï¼ˆå‚è€ƒ WhisperLiveKit çš„ Silero VADï¼‰
    
    ä½¿ç”¨å¤šç‰¹å¾æ£€æµ‹ï¼š
    - RMSï¼ˆå‡æ–¹æ ¹ï¼‰
    - è¿‡é›¶ç‡ï¼ˆZero Crossing Rateï¼‰
    - é¢‘è°±èƒ½é‡
    
    âš¡ é’ˆå¯¹ç³»ç»ŸéŸ³é¢‘ä¼˜åŒ–ï¼šç³»ç»ŸéŸ³é¢‘éŸ³é‡é€šå¸¸æ¯”éº¦å…‹é£ä½å¾ˆå¤šï¼Œéœ€è¦æ›´æ•æ„Ÿçš„æ£€æµ‹
    """
    
    def __init__(self, threshold: float = 0.01, min_silence_duration: float = 0.3, is_system_audio: bool = False):
        # âš¡ ç³»ç»ŸéŸ³é¢‘ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ï¼ˆéŸ³é‡é€šå¸¸æ¯”éº¦å…‹é£ä½ 10-20dBï¼‰
        if is_system_audio:
            self.threshold = threshold * 0.1  # é™ä½åˆ°åŸæ¥çš„ 10%
            logger.info(f"ğŸ¯ ç³»ç»ŸéŸ³é¢‘æ¨¡å¼ï¼šVAD é˜ˆå€¼é™ä½åˆ° {self.threshold:.6f}ï¼ˆåŸé˜ˆå€¼ï¼š{threshold:.6f}ï¼‰")
        else:
            self.threshold = threshold
        self.min_silence_duration = min_silence_duration
        self.voice_started = False
        self.silence_duration = 0.0
        self.sample_rate = 16000
        self.is_system_audio = is_system_audio
    
    def detect(self, audio_array: np.ndarray) -> Optional[str]:
        """æ£€æµ‹è¯­éŸ³äº‹ä»¶
        
        Returns:
            "VOICE_STARTED": è¯­éŸ³å¼€å§‹
            "VOICE_ENDED": è¯­éŸ³ç»“æŸ
            None: æ— äº‹ä»¶
        """
        has_voice = self._detect_voice(audio_array)
        duration = len(audio_array) / self.sample_rate
        
        if has_voice:
            if not self.voice_started:
                self.voice_started = True
                self.silence_duration = 0.0
                return "VOICE_STARTED"
            self.silence_duration = 0.0
        else:
            if self.voice_started:
                self.silence_duration += duration
                if self.silence_duration >= self.min_silence_duration:
                    self.voice_started = False
                    self.silence_duration = 0.0
                    return "VOICE_ENDED"
        
        return None
    
    def _detect_voice(self, audio_array: np.ndarray) -> bool:
        """å¤šç‰¹å¾è¯­éŸ³æ£€æµ‹"""
        if len(audio_array) == 0:
            return False
        
        # ç‰¹å¾1: RMSï¼ˆå‡æ–¹æ ¹ï¼‰
        rms = np.sqrt(np.mean(audio_array ** 2))
        
        # ç‰¹å¾2: è¿‡é›¶ç‡ï¼ˆZero Crossing Rateï¼‰
        zcr = np.mean(np.abs(np.diff(np.sign(audio_array)))) / 2.0
        
        # ç‰¹å¾3: é¢‘è°±èƒ½é‡ï¼ˆç®€å•ç‰ˆæœ¬ï¼šé«˜é¢‘èƒ½é‡ï¼‰
        fft = np.fft.rfft(audio_array)
        spectral_energy = np.sum(np.abs(fft) ** 2)
        
        # âš¡ ç³»ç»ŸéŸ³é¢‘ä¼˜åŒ–ï¼šä½¿ç”¨æ›´å®½æ¾çš„æ£€æµ‹æ¡ä»¶
        if self.is_system_audio:
            # ç³»ç»ŸéŸ³é¢‘ï¼šé™ä½æ‰€æœ‰é˜ˆå€¼ï¼Œæé«˜çµæ•åº¦
            zcr_threshold = 0.05  # é™ä½è¿‡é›¶ç‡é˜ˆå€¼
            spectral_threshold = 100  # é™ä½é¢‘è°±èƒ½é‡é˜ˆå€¼ï¼ˆä» 1000 é™åˆ° 100ï¼‰
            
            # ç»¼åˆåˆ¤æ–­ï¼šæ›´å®½æ¾çš„æ¡ä»¶
            voice_detected = (
                rms > self.threshold or
                (rms > self.threshold * 0.3 and zcr > zcr_threshold) or  # é™ä½ RMS è¦æ±‚
                (rms > self.threshold * 0.2 and spectral_energy > spectral_threshold)  # è¿›ä¸€æ­¥é™ä½è¦æ±‚
            )
        else:
            # éº¦å…‹é£éŸ³é¢‘ï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
            voice_detected = (
                rms > self.threshold or
                (rms > self.threshold * 0.5 and zcr > 0.1 and spectral_energy > 1000)
            )
        
        return voice_detected
    
    def has_silence(self) -> bool:
        """å½“å‰æ˜¯å¦æœ‰é™éŸ³"""
        return self.silence_duration >= self.min_silence_duration


class StreamingPolicy:
    """æµå¼ç­–ç•¥ï¼ˆå‚è€ƒ WhisperLiveKit çš„æ™ºèƒ½æäº¤ç­–ç•¥ï¼‰
    
    å†³å®šä½•æ—¶æäº¤éƒ¨åˆ†ç»“æœï¼Œä½•æ—¶æäº¤æœ€ç»ˆç»“æœ
    """
    
    def __init__(
        self,
        min_chunk_duration: float = 0.3,
        max_chunk_duration: float = 2.0,
        silence_threshold: float = 0.5,
    ):
        self.min_chunk_duration = min_chunk_duration
        self.max_chunk_duration = max_chunk_duration
        self.silence_threshold = silence_threshold
    
    def should_commit(
        self,
        audio_duration: float,
        has_silence: bool,
        text_length: int = 0,
        is_voice_ended: bool = False,
    ) -> tuple[bool, bool]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æäº¤ç»“æœï¼ˆå‚è€ƒ WhisperLiveKit çš„æ™ºèƒ½ç­–ç•¥ï¼‰
        
        âš¡ å‚è€ƒ WhisperLiveKit çš„æµå¼ç­–ç•¥ï¼š
        - æ”¯æŒéƒ¨åˆ†ç»“æœï¼ˆisFinal=Falseï¼‰ï¼šå®æ—¶æ›´æ–°ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
        - æ”¯æŒæœ€ç»ˆç»“æœï¼ˆisFinal=Trueï¼‰ï¼šè¯­å¥ç»“æŸæ—¶æäº¤ï¼Œç¡®ä¿å‡†ç¡®æ€§
        
        Returns:
            (should_commit, is_final): æ˜¯å¦æäº¤ï¼Œæ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
        """
        # ç­–ç•¥1: æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ + æœ‰æ–‡æœ¬ â†’ æäº¤æœ€ç»ˆç»“æœ
        if is_voice_ended and text_length >= 1:
            return True, True
        
        # ç­–ç•¥2: æœ‰é™éŸ³ + æœ‰æ–‡æœ¬ + éŸ³é¢‘æ—¶é•¿è¶³å¤Ÿ â†’ æäº¤æœ€ç»ˆç»“æœï¼ˆè¯­å¥ç»“æŸï¼‰
        if has_silence and text_length >= 1 and audio_duration >= self.min_chunk_duration:
            return True, True
        
        # ç­–ç•¥3: çŸ­å¥ï¼ˆ<1ç§’ï¼‰+ æœ‰æ–‡æœ¬ + æœ‰é™éŸ³ â†’ å¯èƒ½æ˜¯å®Œæ•´çŸ­å¥
        if audio_duration < 1.0 and text_length >= 1 and has_silence:
            return True, True
        
        # ç­–ç•¥4: é•¿å¥ï¼ˆ>=0.3ç§’ï¼‰+ æœ‰æ–‡æœ¬ â†’ æäº¤éƒ¨åˆ†ç»“æœï¼ˆå®æ—¶æ›´æ–°ï¼‰
        # âš¡ å‚è€ƒ WhisperLiveKitï¼šå³ä½¿æ²¡æœ‰é™éŸ³ï¼Œä¹Ÿæäº¤éƒ¨åˆ†ç»“æœï¼Œå®ç°å®æ—¶æ›´æ–°
        # âš¡ å…³é”®ä¿®å¤ï¼šé™ä½é˜ˆå€¼ï¼Œç¡®ä¿æ›´å¤šç»“æœè¢«æäº¤ï¼ˆå®æ—¶æ€§ä¼˜å…ˆï¼‰
        if audio_duration >= self.min_chunk_duration and text_length >= 1:
            # å¦‚æœéŸ³é¢‘æ—¶é•¿è¶…è¿‡æœ€å¤§æ—¶é•¿ï¼Œå¼ºåˆ¶æäº¤æœ€ç»ˆç»“æœ
            if audio_duration >= self.max_chunk_duration:
                return True, True
            # âš¡ å…³é”®ä¿®å¤ï¼šåªè¦æœ‰æ–‡æœ¬å°±æäº¤éƒ¨åˆ†ç»“æœï¼Œä¸ç­‰å¾…é™éŸ³
            # è¿™æ ·å¯ä»¥å®ç°çœŸæ­£çš„å®æ—¶æ›´æ–°ï¼ˆ< 300ms å»¶è¿Ÿï¼‰
            return True, False
        
        # ç­–ç•¥5: æ–‡æœ¬å¤ªçŸ­ â†’ ä¸æäº¤ï¼ˆå¯èƒ½æ˜¯å™ªå£°æˆ–æœªå®Œæˆçš„è¯ï¼‰
        if text_length < 1:
            return False, False
        
        return False, False


class WhisperLiveKitNativeProcessor:
    """WhisperLiveKit åŸç”Ÿå¤„ç†å™¨ - ç›´æ¥å®ç°æ ¸å¿ƒæŠ€æœ¯
    
    ä¸ä¾èµ–ç‹¬ç«‹æœåŠ¡å™¨ï¼Œç›´æ¥ä½¿ç”¨ Faster-Whisper + WhisperLiveKit ç®—æ³•
    """
    
    def __init__(
        self,
        sample_rate: int = 16000,
        chunk_duration: float = 0.3,  # 300ms å¤„ç†å—ï¼ˆè¶…ä½å»¶è¿Ÿï¼‰
        overlap: float = 0.1,  # 100ms é‡å 
        min_samples: int = 4800,  # æœ€å° 0.3 ç§’
        context_duration: float = 1.0,  # ä¸Šä¸‹æ–‡çª—å£ 1 ç§’
        is_system_audio: bool = True,  # âš¡ é»˜è®¤å‡è®¾æ˜¯ç³»ç»ŸéŸ³é¢‘ï¼ˆå› ä¸ºéº¦å…‹é£é€šå¸¸ç”¨ Web Speech APIï¼‰
    ):
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        self.overlap = overlap
        self.min_samples = min_samples
        self.is_system_audio = is_system_audio
        
        # éŸ³é¢‘ç¼“å†²åŒº
        max_buffer_samples = int(sample_rate * 10.0)  # æœ€å¤š 10 ç§’
        max_buffer_size = max_buffer_samples * 2  # Int16 = 2 bytes
        self.pcm_buffer = deque(maxlen=max_buffer_size)
        
        # å¢é‡ä¸Šä¸‹æ–‡ï¼ˆå‚è€ƒ WhisperLiveKitï¼‰
        self.incremental_context = IncrementalContext(
            context_duration=context_duration,
            sample_rate=sample_rate,
        )
        
        # âš¡ æ”¹è¿›çš„ VADï¼ˆç³»ç»ŸéŸ³é¢‘éœ€è¦æ›´ä½çš„é˜ˆå€¼ï¼‰
        # å‚è€ƒ WhisperLiveKitï¼šç³»ç»ŸéŸ³é¢‘éŸ³é‡é€šå¸¸æ¯”éº¦å…‹é£ä½ 10-20dBï¼Œéœ€è¦æ›´æ•æ„Ÿçš„æ£€æµ‹
        # ç³»ç»ŸéŸ³é¢‘ï¼šé˜ˆå€¼é™ä½åˆ° 0.0005ï¼ˆåŸæ¥çš„ 1/10ï¼‰
        # éº¦å…‹é£ï¼šä½¿ç”¨ 0.005ï¼ˆåŸæ¥çš„å€¼ï¼‰
        vad_threshold = 0.0005 if is_system_audio else 0.005
        self.vad = ImprovedVAD(
            threshold=vad_threshold,
            min_silence_duration=0.5,
            is_system_audio=is_system_audio
        )
        
        # âš¡ éŸ³é¢‘è´¨é‡æ£€æµ‹é˜ˆå€¼ï¼ˆç³»ç»ŸéŸ³é¢‘éœ€è¦æ›´ä½çš„é˜ˆå€¼ï¼‰
        # ç³»ç»ŸéŸ³é¢‘éŸ³é‡é€šå¸¸æ¯”éº¦å…‹é£ä½å¾ˆå¤šï¼Œéœ€è¦æ›´å®½æ¾çš„è´¨é‡æ£€æµ‹
        if is_system_audio:
            self.audio_quality_rms_threshold = 0.0001  # é™ä½åˆ°åŸæ¥çš„ 1/10
            self.audio_quality_max_threshold = 0.001  # é™ä½åˆ°åŸæ¥çš„ 1/10
            logger.info(f"ğŸ¯ ç³»ç»ŸéŸ³é¢‘æ¨¡å¼ï¼šéŸ³é¢‘è´¨é‡æ£€æµ‹é˜ˆå€¼é™ä½ï¼ˆRMS: {self.audio_quality_rms_threshold:.6f}, Max: {self.audio_quality_max_threshold:.6f}ï¼‰")
        else:
            self.audio_quality_rms_threshold = 0.001
            self.audio_quality_max_threshold = 0.01
        
        # æµå¼ç­–ç•¥
        self.streaming_policy = StreamingPolicy(
            min_chunk_duration=chunk_duration,
            max_chunk_duration=2.0,
            silence_threshold=0.5,
        )
        
        # å¤„ç†çŠ¶æ€
        self.is_processing = False
        self.last_process_time = time.time()
        self.voice_activity_detected = False
        self.voice_ended_detected = False
        self.total_processed_samples = 0
        self.recognition_start_time = None
        
        logger.info(f"âœ… WhisperLiveKit åŸç”Ÿå¤„ç†å™¨åˆå§‹åŒ–: chunk={chunk_duration}s, overlap={overlap}s, context={context_duration}s")
    
    def add_pcm_data(self, data: bytes):
        """æ¥æ”¶ PCM æ•°æ®ï¼ˆInt16ï¼‰å¹¶æ·»åŠ åˆ°ç¼“å†²åŒº"""
        self.pcm_buffer.extend(data)
        
        # è½¬æ¢ä¸º numpy è¿›è¡Œ VAD æ£€æµ‹
        if len(data) >= 2:
            audio_int16 = np.frombuffer(data, dtype=np.int16)
            audio_float = audio_int16.astype(np.float32) / 32768.0
            
            # VAD äº‹ä»¶æ£€æµ‹
            vad_event = self.vad.detect(audio_float)
            if vad_event:
                logger.debug(f"ğŸ¤ VAD äº‹ä»¶: {vad_event}")
                if vad_event == "VOICE_STARTED":
                    self.voice_activity_detected = True
                elif vad_event == "VOICE_ENDED":
                    self.voice_ended_detected = True
    
    async def try_process(self, model) -> Optional[dict]:
        """å°è¯•å¤„ç†éŸ³é¢‘æ•°æ® - WhisperLiveKit æ ¸å¿ƒç®—æ³•
        
        âš¡ å…³é”®ä¼˜åŒ–ï¼šç¡®ä¿å®æ—¶å¤„ç†ï¼Œä¸ç­‰å¾…
        - æ¯æ¬¡æ”¶åˆ°æ•°æ®åç«‹å³æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤„ç†
        - å³ä½¿æ²¡æœ‰ VAD äº‹ä»¶ï¼Œä¹ŸæŒ‰æ—¶é—´è§¦å‘ï¼ˆ300msï¼‰
        - é¿å…å¤„ç†é˜»å¡å¯¼è‡´æ•°æ®ç§¯å‹
        """
        current_samples = len(self.pcm_buffer) // 2
        current_time = time.time()
        time_since_last = current_time - self.last_process_time
        
        # åˆå§‹åŒ–è¯†åˆ«å¼€å§‹æ—¶é—´
        if self.recognition_start_time is None:
            self.recognition_start_time = current_time
        
        # âš¡ å…³é”®ä¿®å¤ï¼šé™ä½æœ€å°æ ·æœ¬æ•°è¦æ±‚ï¼Œç¡®ä¿æ›´å¿«å“åº”
        # ä» 0.3ç§’ï¼ˆ4800 samplesï¼‰é™ä½åˆ° 0.1ç§’ï¼ˆ1600 samplesï¼‰
        min_samples_for_processing = max(1600, self.min_samples // 3)  # è‡³å°‘ 0.1ç§’
        
        # æ£€æŸ¥å¤„ç†æ¡ä»¶
        has_enough_data = current_samples >= min_samples_for_processing
        event_triggered = self.voice_ended_detected or self.voice_activity_detected
        time_triggered = time_since_last >= self.chunk_duration
        buffer_overflow = current_samples > int(self.sample_rate * 2.0)  # 2ç§’æº¢å‡ºä¿æŠ¤ï¼ˆé™ä½é˜ˆå€¼ï¼‰
        
        # âš¡ å‚è€ƒ WhisperLiveKitï¼šå³ä½¿æ²¡æœ‰ VAD äº‹ä»¶ï¼Œä¹ŸæŒ‰æ—¶é—´è§¦å‘å¤„ç†
        # è¿™æ ·å¯ä»¥ç¡®ä¿ç³»ç»ŸéŸ³é¢‘ï¼ˆå¯èƒ½éŸ³é‡è¾ƒä½ï¼‰ä¹Ÿèƒ½è¢«å¤„ç†
        should_process = has_enough_data and (event_triggered or time_triggered or buffer_overflow)
        
        # âš¡ è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å¤„ç†æ¡ä»¶
        if should_process and not self.is_processing:
            logger.debug(f"ğŸ¯ è§¦å‘å¤„ç†: samples={current_samples}, time_since_last={time_since_last:.3f}s, event={event_triggered}, time={time_triggered}, overflow={buffer_overflow}")
        
        if not should_process:
            return None
        
        # âš¡ å…³é”®ä¿®å¤ï¼šå¦‚æœæ­£åœ¨å¤„ç†ï¼Œä½†ç¼“å†²åŒºæº¢å‡ºæˆ–æ—¶é—´è§¦å‘ï¼Œå…è®¸å¹¶è¡Œå¤„ç†
        # è¿™æ ·å¯ä»¥é¿å…å¤„ç†é€Ÿåº¦æ…¢å¯¼è‡´çš„æ•°æ®ç§¯å‹
        if self.is_processing and not (buffer_overflow or time_triggered):
            return None
        
        # é‡ç½®äº‹ä»¶æ ‡å¿—
        self.voice_activity_detected = False
        self.voice_ended_detected = False
        
        self.is_processing = True
        process_start_time = time.time()
        
        try:
            # æå–è¦å¤„ç†çš„æ•°æ®ï¼ˆchunk_duration é•¿åº¦ï¼‰
            target_samples = int(self.sample_rate * self.chunk_duration)
            process_samples = min(target_samples, current_samples)
            process_bytes = process_samples * 2
            
            pcm_bytes = bytes(list(self.pcm_buffer)[:process_bytes])
            
            if len(pcm_bytes) % 2 != 0:
                pcm_bytes = pcm_bytes[:-1]
                process_bytes = len(pcm_bytes)
                process_samples = process_bytes // 2
            
            # è½¬æ¢ä¸º numpy
            audio_int16 = np.frombuffer(pcm_bytes, dtype=np.int16)
            audio_float = audio_int16.astype(np.float32) / 32768.0
            
            # âš¡ è°ƒè¯•ï¼šæ£€æŸ¥éŸ³é¢‘æ•°æ®è´¨é‡
            audio_rms = np.sqrt(np.mean(audio_float ** 2))
            audio_max = np.max(np.abs(audio_float))
            
            # âš¡ å…³é”®ä¼˜åŒ–ï¼šå¦‚æœéŸ³é¢‘è´¨é‡å¤ªä½ï¼Œè·³è¿‡å¤„ç†
            # âš¡ ç³»ç»ŸéŸ³é¢‘ä¼˜åŒ–ï¼šä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ï¼ˆç³»ç»ŸéŸ³é¢‘éŸ³é‡é€šå¸¸æ¯”éº¦å…‹é£ä½ 10-20dBï¼‰
            # å¯¹äºç³»ç»ŸéŸ³é¢‘ï¼Œå³ä½¿ RMS å¾ˆä½ä¹Ÿå¯èƒ½åŒ…å«æœ‰æ•ˆè¯­éŸ³ï¼Œæ‰€ä»¥é˜ˆå€¼è¦æ›´ä½
            if audio_rms < self.audio_quality_rms_threshold or audio_max < self.audio_quality_max_threshold:
                # âš¡ ç³»ç»ŸéŸ³é¢‘ï¼šå³ä½¿è´¨é‡è¾ƒä½ä¹Ÿè®°å½•æ—¥å¿—ï¼Œä½†ä¸ä¸€å®šè·³è¿‡ï¼ˆå¯èƒ½åŒ…å«æœ‰æ•ˆè¯­éŸ³ï¼‰
                if self.is_system_audio:
                    logger.debug(f"âš ï¸ ç³»ç»ŸéŸ³é¢‘è´¨é‡è¾ƒä½ï¼ˆä½†å¯èƒ½åŒ…å«æœ‰æ•ˆè¯­éŸ³ï¼‰: rms={audio_rms:.6f}, max={audio_max:.6f}, é˜ˆå€¼: rms>{self.audio_quality_rms_threshold:.6f}, max>{self.audio_quality_max_threshold:.6f}")
                    # âš¡ ç³»ç»ŸéŸ³é¢‘ï¼šå³ä½¿è´¨é‡ä½ä¹Ÿå°è¯•å¤„ç†ï¼ˆå¯èƒ½åŒ…å«æœ‰æ•ˆè¯­éŸ³ï¼Œåªæ˜¯éŸ³é‡ä½ï¼‰
                    # ä½†å¦‚æœå®åœ¨å¤ªä½ï¼ˆRMS < 0.00001ï¼‰ï¼Œåˆ™è·³è¿‡ï¼ˆå¯èƒ½æ˜¯å®Œå…¨é™éŸ³ï¼‰
                    if audio_rms < 0.00001 and audio_max < 0.0001:
                        logger.debug(f"âš ï¸ ç³»ç»ŸéŸ³é¢‘å®Œå…¨é™éŸ³ï¼Œè·³è¿‡å¤„ç†: rms={audio_rms:.9f}, max={audio_max:.9f}")
                        samples_to_remove = min(process_samples // 2, len(self.pcm_buffer) // 2)
                        bytes_to_remove = samples_to_remove * 2
                        for _ in range(bytes_to_remove):
                            if self.pcm_buffer:
                                self.pcm_buffer.popleft()
                        return None
                    # å¦åˆ™ç»§ç»­å¤„ç†ï¼ˆå³ä½¿è´¨é‡è¾ƒä½ï¼‰
                else:
                    # éº¦å…‹é£ï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
                    logger.debug(f"âš ï¸ éŸ³é¢‘è´¨é‡å¤ªä½ï¼Œè·³è¿‡å¤„ç†: rms={audio_rms:.6f}, max={audio_max:.6f}")
                    samples_to_remove = min(process_samples // 2, len(self.pcm_buffer) // 2)
                    bytes_to_remove = samples_to_remove * 2
                    for _ in range(bytes_to_remove):
                        if self.pcm_buffer:
                            self.pcm_buffer.popleft()
                    return None
            
            # âš¡ è¯¦ç»†æ—¥å¿—ï¼šè®°å½•éŸ³é¢‘è´¨é‡ï¼ˆç‰¹åˆ«æ˜¯ç³»ç»ŸéŸ³é¢‘ï¼‰
            if self.is_system_audio:
                logger.debug(f"ğŸ“Š ç³»ç»ŸéŸ³é¢‘æ•°æ®: samples={len(audio_float)}, rms={audio_rms:.6f}, max={audio_max:.6f}, é˜ˆå€¼: rms>{self.audio_quality_rms_threshold:.6f}, max>{self.audio_quality_max_threshold:.6f}")
            else:
                logger.debug(f"ğŸ“Š éŸ³é¢‘æ•°æ®: samples={len(audio_float)}, rms={audio_rms:.6f}, max={audio_max:.6f}")
            
            # ä½¿ç”¨å¢é‡ä¸Šä¸‹æ–‡ï¼ˆå‚è€ƒ WhisperLiveKitï¼‰
            audio_with_context = self.incremental_context.get_context_audio(audio_float)
            
            # ç§»é™¤å·²å¤„ç†çš„æ•°æ®ï¼ˆä¿ç•™é‡å éƒ¨åˆ†ï¼‰
            overlap_samples = int(self.sample_rate * self.overlap)
            samples_to_remove = max(0, process_samples - overlap_samples)
            bytes_to_remove = samples_to_remove * 2
            
            for _ in range(bytes_to_remove):
                if self.pcm_buffer:
                    self.pcm_buffer.popleft()
            
            # è¯†åˆ«
            # âš¡ å‚è€ƒ WhisperLiveKitï¼šæ—¶é—´æˆ³åŸºäºå®é™…å¤„ç†çš„éŸ³é¢‘å—ï¼ˆä¸åŒ…å«ä¸Šä¸‹æ–‡ï¼‰
            # ä¸Šä¸‹æ–‡åªæ˜¯ç”¨äºæé«˜è¯†åˆ«å‡†ç¡®æ€§ï¼Œä¸å½±å“æ—¶é—´æˆ³
            actual_audio_duration = len(audio_float) / self.sample_rate  # å®é™…å¤„ç†çš„éŸ³é¢‘æ—¶é•¿
            result = await self._transcribe(model, audio_with_context, self.voice_ended_detected)
            
            if result:
                # âš¡ å‚è€ƒ WhisperLiveKitï¼šè®¡ç®—ç²¾ç¡®çš„æ—¶é—´æˆ³
                # åŸºäºå®é™…å¤„ç†çš„éŸ³é¢‘å—é•¿åº¦ï¼Œè€Œä¸æ˜¯åŒ…å«ä¸Šä¸‹æ–‡çš„é•¿åº¦
                relative_time = time.time() - self.recognition_start_time
                # start_time åº”è¯¥æ˜¯å½“å‰æ—¶é—´å‡å»å®é™…å¤„ç†çš„éŸ³é¢‘æ—¶é•¿
                start_time = max(0.0, relative_time - actual_audio_duration)
                end_time = relative_time
                
                result['startTime'] = start_time
                result['endTime'] = end_time
                
                self.total_processed_samples += process_samples
                self.last_process_time = process_start_time
            
            return result
            
        except Exception as e:
            logger.error(f"å¤„ç†éŸ³é¢‘å¤±è´¥: {e}", exc_info=True)
            return None
        finally:
            self.is_processing = False
    
    async def _transcribe(self, model, audio_array: np.ndarray, voice_ended: bool = False) -> Optional[dict]:
        """ä½¿ç”¨ Faster-Whisper è¿›è¡Œè½¬å½•ï¼ˆå‚è€ƒ WhisperLiveKit å‚æ•°ï¼‰
        
        âš¡ ç³»ç»ŸéŸ³é¢‘ä¼˜åŒ–ï¼šé’ˆå¯¹ä½éŸ³é‡ç‰¹æ€§è°ƒæ•´å‚æ•°
        """
        try:
            loop = asyncio.get_event_loop()
            
            def transcribe_task():
                # âš¡ å‚è€ƒ WhisperLiveKitï¼šä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„ VADï¼Œç¦ç”¨ Faster-Whisper çš„ VAD
                # å› ä¸ºç³»ç»ŸéŸ³é¢‘çš„éŸ³é‡å¯èƒ½è¾ƒä½ï¼ŒFaster-Whisper çš„ VAD é˜ˆå€¼å¤ªé«˜ä¼šè¿‡æ»¤æ‰æ‰€æœ‰éŸ³é¢‘
                # æˆ‘ä»¬å·²ç»åœ¨ add_pcm_data ä¸­åšäº† VAD æ£€æµ‹ï¼Œè¿™é‡Œç›´æ¥è½¬å½•
                
                # âš¡ ç³»ç»ŸéŸ³é¢‘ä¼˜åŒ–ï¼šä½¿ç”¨æ›´å®½æ¾çš„å‚æ•°ï¼Œé€‚é…ä½éŸ³é‡ç‰¹æ€§
                if self.is_system_audio:
                    # ç³»ç»ŸéŸ³é¢‘ï¼šæ›´å®½æ¾çš„é˜ˆå€¼ï¼Œæé«˜è¯†åˆ«çµæ•åº¦
                    transcribe_params = {
                        "beam_size": 5,  # æé«˜ beam_size æå‡å‡†ç¡®æ€§
                        "language": "zh",
                        "task": "transcribe",
                        "vad_filter": False,  # âš¡ ç¦ç”¨ Faster-Whisper çš„ VADï¼Œä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„ ImprovedVAD
                        "condition_on_previous_text": True,  # âš¡ å¯ç”¨ä¸Šä¸‹æ–‡æ¡ä»¶ï¼Œæå‡å‡†ç¡®æ€§
                        "best_of": 5,  # âš¡ æé«˜ best_of æå‡å‡†ç¡®æ€§
                        "temperature": 0.0,  # âš¡ ä½¿ç”¨ç¡®å®šæ€§è§£ç ï¼Œæå‡å‡†ç¡®æ€§
                        "compression_ratio_threshold": 2.4,  # âš¡ å‹ç¼©æ¯”é˜ˆå€¼ï¼Œè¿‡æ»¤é‡å¤æ–‡æœ¬
                        "log_prob_threshold": -1.5,  # âš¡ ç³»ç»ŸéŸ³é¢‘ï¼šé™ä½é˜ˆå€¼ï¼ˆä» -1.0 é™åˆ° -1.5ï¼‰ï¼Œå…è®¸æ›´å¤šä½éŸ³é‡ç»“æœ
                        "no_speech_threshold": 0.3,  # âš¡ ç³»ç»ŸéŸ³é¢‘ï¼šå¤§å¹…é™ä½æ— è¯­éŸ³é˜ˆå€¼ï¼ˆä» 0.5 é™åˆ° 0.3ï¼‰ï¼Œæ›´æ•æ„Ÿ
                        "initial_prompt": "è¿™æ˜¯ä¸€æ®µä¸­æ–‡è¯­éŸ³è½¬å½•ã€‚",  # âš¡ æ·»åŠ åˆå§‹æç¤ºï¼Œæå‡ä¸­æ–‡è¯†åˆ«å‡†ç¡®æ€§
                    }
                    logger.debug(f"ğŸ¯ ç³»ç»ŸéŸ³é¢‘æ¨¡å¼ï¼šä½¿ç”¨ä¼˜åŒ–çš„è½¬å½•å‚æ•°ï¼ˆno_speech_threshold=0.3, log_prob_threshold=-1.5ï¼‰")
                else:
                    # éº¦å…‹é£ï¼šä½¿ç”¨åŸæœ‰å‚æ•°
                    transcribe_params = {
                        "beam_size": 5,
                        "language": "zh",
                        "task": "transcribe",
                        "vad_filter": False,
                        "condition_on_previous_text": True,
                        "best_of": 5,
                        "temperature": 0.0,
                        "compression_ratio_threshold": 2.4,
                        "log_prob_threshold": -1.0,
                        "no_speech_threshold": 0.5,
                        "initial_prompt": "è¿™æ˜¯ä¸€æ®µä¸­æ–‡è¯­éŸ³è½¬å½•ã€‚",
                    }
                
                segments, info = model.transcribe(audio_array, **transcribe_params)
                return list(segments), info
            
            segments_list, info = await loop.run_in_executor(None, transcribe_task)
            
            if not segments_list:
                return None
            
            # âš¡ å…³é”®ä¿®å¤ï¼šåˆå¹¶æ‰€æœ‰ç‰‡æ®µï¼Œå¹¶è¿‡æ»¤é‡å¤æ–‡æœ¬
            text = "".join(seg.text for seg in segments_list)
            text = convert_traditional_to_simplified(text.strip())
            
            # âš¡ è¿‡æ»¤é‡å¤æ–‡æœ¬ï¼ˆä¸­æ–‡æŒ‰å­—ç¬¦æ£€æŸ¥ï¼Œè‹±æ–‡æŒ‰è¯æ£€æŸ¥ï¼‰
            if len(text) > 0:
                # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤æ¨¡å¼ï¼ˆå¦‚"è®¤è®¤è®¤è®¤..."æˆ–"å¿«å¿«å¿«å¿«..."ï¼‰
                # ä¸­æ–‡ï¼šæ£€æŸ¥è¿ç»­é‡å¤çš„å­—ç¬¦
                chars = list(text)
                if len(chars) > 3:
                    repeat_count = 0
                    max_repeat = 0
                    for i in range(1, len(chars)):
                        if chars[i] == chars[i-1]:
                            repeat_count += 1
                            max_repeat = max(max_repeat, repeat_count)
                        else:
                            repeat_count = 0
                    
                    # âš¡ å¦‚æœè¿ç»­é‡å¤è¶…è¿‡3ä¸ªå­—ç¬¦ï¼Œè®¤ä¸ºæ˜¯é”™è¯¯è¯†åˆ«
                    if max_repeat >= 3:
                        logger.warning(f"æ£€æµ‹åˆ°é‡å¤æ–‡æœ¬ï¼Œå¯èƒ½è¯†åˆ«é”™è¯¯: {text[:50]}...")
                        return None  # è¿‡æ»¤æ‰é‡å¤æ–‡æœ¬
                    
                    # âš¡ é¢å¤–æ£€æŸ¥ï¼šå¦‚æœæ•´ä¸ªæ–‡æœ¬éƒ½æ˜¯åŒä¸€ä¸ªå­—ç¬¦ï¼Œè¿‡æ»¤æ‰
                    if len(set(chars)) == 1 and len(chars) > 2:
                        logger.warning(f"æ£€æµ‹åˆ°å•ä¸€å­—ç¬¦é‡å¤ï¼Œå¯èƒ½è¯†åˆ«é”™è¯¯: {text[:50]}...")
                        return None
            
            if not text:
                return None
            
            # ä½¿ç”¨æµå¼ç­–ç•¥å†³å®šæ˜¯å¦æäº¤
            audio_duration = len(audio_array) / self.sample_rate
            has_silence = self.vad.has_silence()
            should_commit, is_final = self.streaming_policy.should_commit(
                audio_duration=audio_duration,
                has_silence=has_silence,
                text_length=len(text),
                is_voice_ended=voice_ended,
            )
            
            # âš¡ å…³é”®ä¿®å¤ï¼šå¦‚æœæµå¼ç­–ç•¥æ‹’ç»æäº¤ï¼Œä½†æ–‡æœ¬é•¿åº¦è¶³å¤Ÿï¼Œå¼ºåˆ¶æäº¤éƒ¨åˆ†ç»“æœ
            # è¿™æ ·å¯ä»¥ç¡®ä¿å®æ—¶æ€§ï¼Œä¸ä¸¢å¤±è¯†åˆ«ç»“æœ
            if not should_commit:
                # å¦‚æœæ–‡æœ¬é•¿åº¦ >= 1ï¼Œå¼ºåˆ¶æäº¤éƒ¨åˆ†ç»“æœï¼ˆå®æ—¶æ€§ä¼˜å…ˆï¼‰
                if len(text) >= 1 and audio_duration >= 0.1:  # è‡³å°‘ 0.1ç§’
                    should_commit = True
                    is_final = False
                else:
                    return None
            
            return {
                'text': text,
                'isFinal': is_final,
            }
            
        except Exception as e:
            logger.error(f"è½¬å½•å¤±è´¥: {e}", exc_info=True)
            return None
    
    async def flush(self, model) -> Optional[dict]:
        """åˆ·æ–°å‰©ä½™æ•°æ®"""
        if len(self.pcm_buffer) >= self.min_samples:
            # å¤„ç†å‰©ä½™æ•°æ®
            pcm_bytes = bytes(self.pcm_buffer)
            if len(pcm_bytes) >= 2:
                audio_int16 = np.frombuffer(pcm_bytes, dtype=np.int16)
                audio_float = audio_int16.astype(np.float32) / 32768.0
                audio_with_context = self.incremental_context.get_context_audio(audio_float)
                
                result = await self._transcribe(model, audio_with_context, voice_ended=True)
                if result:
                    result['isFinal'] = True
                return result
        return None


@router.websocket("/stream")
async def stream_transcription_native(websocket: WebSocket):
    """
    å®æ—¶è¯­éŸ³è¯†åˆ« WebSocket ç«¯ç‚¹ - ç›´æ¥å®ç° WhisperLiveKit æ ¸å¿ƒæŠ€æœ¯
    
    ä¸ä¾èµ–ç‹¬ç«‹æœåŠ¡å™¨ï¼Œç›´æ¥ä½¿ç”¨ Faster-Whisper + WhisperLiveKit ç®—æ³•
    å®ç°è¶…ä½å»¶è¿Ÿå®æ—¶è½¬å½•ï¼ˆ< 300msï¼‰
    
    å‚è€ƒ WhisperLiveKit å®ç°ï¼š
    - æ”¯æŒ keepalive ping/pong æœºåˆ¶ï¼Œé˜²æ­¢è¿æ¥è¶…æ—¶
    - å®æ—¶å¤„ç†éŸ³é¢‘æµï¼Œæ”¯æŒéƒ¨åˆ†ç»“æœ
    - äº‹ä»¶é©±åŠ¨çš„ VAD å’Œæ™ºèƒ½æµå¼ç­–ç•¥
    """
    await websocket.accept()
    logger.info("WebSocket è¿æ¥å·²å»ºç«‹ï¼ˆWhisperLiveKit åŸç”Ÿå®ç°ï¼‰")
    
    # è·å– Faster-Whisper æ¨¡å‹
    try:
        from lifetrace.routers.voice_stream_whisper import get_whisper_model
        model = await get_whisper_model()
    except ImportError as e:
        error_msg = str(e)
        logger.error(f"Faster-Whisper æœªå®‰è£…: {error_msg}")
        await websocket.send_json({
            "error": "Faster-Whisper æœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œå®æ—¶è¯†åˆ«",
            "details": error_msg,
        })
        await websocket.close()
        return
    
    # åˆ›å»º WhisperLiveKit åŸç”Ÿå¤„ç†å™¨
    # âš¡ å…³é”®ä¼˜åŒ–ï¼šå¢åŠ  chunk_duration æå‡è¯†åˆ«å‡†ç¡®æ€§
    # ä» 0.3ç§’ å¢åŠ åˆ° 0.6ç§’ï¼Œæä¾›æ›´å¤šä¸Šä¸‹æ–‡ï¼Œæå‡è¯†åˆ«å‡†ç¡®æ€§
    # âš¡ ç³»ç»ŸéŸ³é¢‘ä¼˜åŒ–ï¼šé»˜è®¤å‡è®¾æ˜¯ç³»ç»ŸéŸ³é¢‘ï¼ˆå› ä¸ºéº¦å…‹é£é€šå¸¸ä½¿ç”¨ Web Speech APIï¼‰
    processor = WhisperLiveKitNativeProcessor(
        sample_rate=16000,
        chunk_duration=0.6,  # 600msï¼ˆå¹³è¡¡å»¶è¿Ÿå’Œå‡†ç¡®æ€§ï¼‰
        overlap=0.2,  # 200ms é‡å ï¼ˆå¢åŠ é‡å ï¼Œç¡®ä¿ä¸ä¸¢å¤±è¾¹ç•Œï¼‰
        min_samples=4800,  # 0.3 ç§’ï¼ˆæœ€å°å¤„ç†å—ï¼‰
        context_duration=2.0,  # 2 ç§’ä¸Šä¸‹æ–‡ï¼ˆå¢åŠ ä¸Šä¸‹æ–‡ï¼Œæå‡å‡†ç¡®æ€§ï¼‰
        is_system_audio=True,  # âš¡ é»˜è®¤å‡è®¾æ˜¯ç³»ç»ŸéŸ³é¢‘ï¼ˆä¼˜åŒ–ä½éŸ³é‡å¤„ç†ï¼‰
    )
    
    # âš¡ å‚è€ƒ WhisperLiveKitï¼šæ·»åŠ  keepalive ping ä»»åŠ¡
    # æ¯ 20 ç§’å‘é€ä¸€æ¬¡ pingï¼Œé˜²æ­¢è¿æ¥è¶…æ—¶ï¼ˆé™ä½é—´éš”ï¼Œæ›´é¢‘ç¹æ£€æŸ¥ï¼‰
    keepalive_interval = 20.0  # 20 ç§’ï¼ˆé™ä½é—´éš”ï¼Œæ›´é¢‘ç¹æ£€æŸ¥ï¼‰
    last_ping_time = time.time()
    last_pong_time = time.time()  # âš¡ æ·»åŠ ï¼šè®°å½•æœ€åä¸€æ¬¡æ”¶åˆ° pong çš„æ—¶é—´
    ping_task = None
    
    async def send_keepalive_ping():
        """å‘é€ keepalive ping"""
        nonlocal last_ping_time, last_pong_time  # âš¡ ä¿®å¤ï¼šä½¿ç”¨ nonlocal è®¿é—®å¤–éƒ¨å˜é‡
        while True:
            try:
                await asyncio.sleep(keepalive_interval)
                
                # âš¡ æ£€æŸ¥ï¼šå¦‚æœè¶…è¿‡ 60 ç§’æ²¡æœ‰æ”¶åˆ° pongï¼Œè®¤ä¸ºè¿æ¥å·²æ–­å¼€
                if time.time() - last_pong_time > 60.0:
                    logger.warning("è¶…è¿‡ 60 ç§’æœªæ”¶åˆ° pongï¼Œè¿æ¥å¯èƒ½å·²æ–­å¼€")
                    break
                
                if websocket.client_state.name == 'CONNECTED':
                    # å‘é€ pingï¼ˆä½¿ç”¨ JSON æ ¼å¼ï¼Œä¾¿äºå‰ç«¯å¤„ç†ï¼‰
                    await websocket.send_json({"type": "ping", "timestamp": time.time()})
                    last_ping_time = time.time()
                    logger.debug(f"ğŸ“¤ å‘é€ keepalive ping (ç­‰å¾… pongï¼Œä¸Šæ¬¡ pong: {time.time() - last_pong_time:.1f}ç§’å‰)")
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.warning(f"å‘é€ keepalive ping å¤±è´¥: {e}")
                break
    
    # å¯åŠ¨ keepalive ä»»åŠ¡
    ping_task = asyncio.create_task(send_keepalive_ping())
    
    try:
        while True:
            try:
                # âš¡ å‚è€ƒ WhisperLiveKitï¼šä½¿ç”¨ timeout é¿å…é˜»å¡
                # å¦‚æœ 30 ç§’å†…æ²¡æœ‰æ”¶åˆ°æ¶ˆæ¯ï¼Œæ£€æŸ¥è¿æ¥çŠ¶æ€ï¼ˆé™ä½è¶…æ—¶æ—¶é—´ï¼‰
                try:
                    message = await asyncio.wait_for(websocket.receive(), timeout=30.0)
                except asyncio.TimeoutError:
                    # âš¡ è¶…æ—¶æ£€æŸ¥ï¼šå¦‚æœé•¿æ—¶é—´æ²¡æœ‰æ•°æ®ï¼Œæ£€æŸ¥è¿æ¥çŠ¶æ€
                    # æ³¨æ„ï¼šlast_pong_time åœ¨å¤–éƒ¨ä½œç”¨åŸŸï¼Œå¯ä»¥ç›´æ¥è®¿é—®
                    time_since_last_pong = time.time() - last_pong_time
                    if time_since_last_pong > 60.0:
                        logger.warning(f"è¶…è¿‡ 60 ç§’æœªæ”¶åˆ° pong ({time_since_last_pong:.1f}ç§’)ï¼Œè¿æ¥å¯èƒ½å·²æ–­å¼€")
                        break
                    # å¦‚æœè¶…æ—¶ä½†æ²¡æœ‰æ•°æ®ï¼Œç»§ç»­ç­‰å¾…ï¼ˆkeepalive ping ä»»åŠ¡ä¼šå¤„ç†ï¼‰
                    continue
                
                if "bytes" in message:
                    # âš¡ å‚è€ƒ WhisperLiveKitï¼šæ¥æ”¶äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®ï¼ˆPCM Int16, 16kHz, å•å£°é“ï¼‰
                    audio_data = message["bytes"]
                    processor.add_pcm_data(audio_data)
                    
                    # âš¡ å…³é”®ä¿®å¤ï¼šæ¯æ¬¡æ”¶åˆ°æ•°æ®åç«‹å³å°è¯•å¤„ç†ï¼ˆäº‹ä»¶é©±åŠ¨ï¼‰
                    # ä¸ç­‰å¾…æ—¶é—´æ¡ä»¶ï¼Œç«‹å³æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤„ç†
                    # è¿™æ ·å¯ä»¥å®ç°çœŸæ­£çš„å®æ—¶å¤„ç†ï¼ˆ< 300ms å»¶è¿Ÿï¼‰
                    result = await processor.try_process(model)
                    
                    if result:
                        # âš¡ å‚è€ƒ WhisperLiveKitï¼šæ”¯æŒéƒ¨åˆ†ç»“æœå’Œæœ€ç»ˆç»“æœ
                        # éƒ¨åˆ†ç»“æœï¼ˆisFinal=Falseï¼‰ï¼šå®æ—¶æ›´æ–°ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
                        # æœ€ç»ˆç»“æœï¼ˆisFinal=Trueï¼‰ï¼šè¯­å¥ç»“æŸï¼Œç¡®ä¿å‡†ç¡®æ€§
                        await websocket.send_json({
                            "text": result.get('text', ''),
                            "isFinal": result.get('isFinal', False),
                            "startTime": result.get('startTime', 0),
                            "endTime": result.get('endTime', 0),
                        })
                        logger.info(f"âœ… å‘é€è¯†åˆ«ç»“æœ: text={result.get('text', '')[:50]}..., isFinal={result.get('isFinal', False)}, startTime={result.get('startTime', 0):.2f}s")
                
                elif "text" in message:
                    text_msg = message["text"]
                    
                    # âš¡ å¤„ç† keepalive pong
                    if text_msg == "pong":
                        # âš¡ ä¿®å¤ï¼šæ›´æ–° pong æ—¶é—´ï¼ˆåœ¨å¤–éƒ¨ä½œç”¨åŸŸï¼Œå¯ä»¥ç›´æ¥è®¿é—®ï¼‰
                        last_pong_time = time.time()
                        logger.debug(f"ğŸ“¥ æ”¶åˆ° keepalive pong (è·ç¦»ä¸Šæ¬¡ ping: {time.time() - last_ping_time:.1f}ç§’)")
                        continue
                    
                    if text_msg == "EOS":  # End of Stream
                        # å¤„ç†å‰©ä½™æ•°æ®
                        final_result = await processor.flush(model)
                        if final_result:
                            await websocket.send_json({
                                "text": final_result.get('text', ''),
                                "isFinal": True,
                                "startTime": final_result.get('startTime', 0),
                                "endTime": final_result.get('endTime', 0),
                            })
                        break
                
            except WebSocketDisconnect:
                logger.info("WebSocket è¿æ¥å·²æ–­å¼€")
                break
            except Exception as e:
                logger.error(f"WebSocket å¤„ç†é”™è¯¯: {e}", exc_info=True)
                try:
                    await websocket.send_json({
                        "error": f"å¤„ç†é”™è¯¯: {str(e)}",
                    })
                except Exception:
                    pass
                break
    
    except asyncio.CancelledError:
        logger.info("WebSocket ä»»åŠ¡è¢«å–æ¶ˆ")
    except Exception as e:
        logger.error(f"WebSocket è¿æ¥é”™è¯¯: {e}", exc_info=True)
    finally:
        # å–æ¶ˆ keepalive ä»»åŠ¡
        if ping_task:
            ping_task.cancel()
            try:
                await ping_task
            except asyncio.CancelledError:
                pass
        
        try:
            if websocket.client_state.name != 'DISCONNECTED':
                await websocket.close()
        except Exception:
            pass
        logger.info("WebSocket è¿æ¥å·²å…³é—­")

