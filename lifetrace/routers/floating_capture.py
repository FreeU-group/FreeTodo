"""æ‚¬æµ®çª—æˆªå›¾å¾…åŠæå–è·¯ç”±"""

import base64
import json
import os
import re
import time
import uuid
from datetime import datetime
from typing import Any

from fastapi import APIRouter, HTTPException

from lifetrace.llm.llm_client import LLMClient
from lifetrace.schemas.floating_capture import (
    CreatedTodo,
    ExtractedTodo,
    FloatingCaptureRequest,
    FloatingCaptureResponse,
)
from lifetrace.storage import todo_mgr
from lifetrace.util.logging_config import get_logger
from lifetrace.util.prompt_loader import get_prompt
from lifetrace.util.settings import settings
from lifetrace.util.time_parser import calculate_scheduled_time

logger = get_logger()

router = APIRouter(prefix="/api/floating-capture", tags=["floating-capture"])

# LLM å®¢æˆ·ç«¯å•ä¾‹
_llm_client: LLMClient | None = None


def get_llm_client() -> LLMClient:
    """è·å– LLM å®¢æˆ·ç«¯å•ä¾‹"""
    global _llm_client
    if _llm_client is None:
        _llm_client = LLMClient()
    return _llm_client


@router.post("/extract-todos", response_model=FloatingCaptureResponse)
async def extract_todos_from_capture(request: FloatingCaptureRequest) -> FloatingCaptureResponse:
    """
    ä»æ‚¬æµ®çª—æˆªå›¾ä¸­æå–å¾…åŠäº‹é¡¹

    Args:
        request: åŒ…å« base64 ç¼–ç æˆªå›¾çš„è¯·æ±‚

    Returns:
        æå–å’Œåˆ›å»ºçš„å¾…åŠäº‹é¡¹åˆ—è¡¨
    """
    try:
        total_start = time.time()
        logger.info("ğŸš€ å¼€å§‹å¤„ç†æ‚¬æµ®çª—æˆªå›¾è¯·æ±‚...")
        
        llm_client = get_llm_client()

        if not llm_client.is_available():
            return FloatingCaptureResponse(
                success=False,
                message="LLM æœåŠ¡å½“å‰ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®",
                extracted_todos=[],
                created_todos=[],
                created_count=0,
            )

        # è·å–å·²æœ‰å¾…åŠåˆ—è¡¨ç”¨äºå»é‡
        step_start = time.time()
        existing_todos = todo_mgr.list_todos(limit=1000, status="active")
        existing_todos += todo_mgr.list_todos(limit=1000, status="draft")
        logger.info(f"â±ï¸ è·å–å·²æœ‰å¾…åŠåˆ—è¡¨: {time.time() - step_start:.3f}s (å…± {len(existing_todos)} æ¡)")

        # è°ƒç”¨è§†è§‰æ¨¡å‹æå–å¾…åŠ
        step_start = time.time()
        extracted_todos = _call_vision_model_with_base64(
            llm_client=llm_client,
            image_base64=request.image_base64,
            existing_todos=existing_todos,
        )
        logger.info(f"â±ï¸ è§†è§‰æ¨¡å‹è°ƒç”¨æ€»è€—æ—¶: {time.time() - step_start:.3f}s")

        if not extracted_todos:
            return FloatingCaptureResponse(
                success=True,
                message="æˆªå›¾ä¸­æœªæ£€æµ‹åˆ°å¾…åŠäº‹é¡¹",
                extracted_todos=[],
                created_todos=[],
                created_count=0,
            )

        # è½¬æ¢ä¸º ExtractedTodo åˆ—è¡¨
        extracted_todo_models = [
            ExtractedTodo(
                title=todo.get("title", ""),
                description=todo.get("description"),
                time_info=todo.get("time_info"),
                source_text=todo.get("source_text"),
                confidence=todo.get("confidence", 0.5),
            )
            for todo in extracted_todos
        ]

        # å¦‚æœéœ€è¦åˆ›å»ºå¾…åŠ
        created_todos: list[CreatedTodo] = []
        created_count = 0

        if request.create_todos:
            step_start = time.time()
            for todo_data in extracted_todos:
                try:
                    result = _create_draft_todo(todo_data)
                    if result:
                        created_count += 1
                        created_todos.append(
                            CreatedTodo(
                                id=result["id"],
                                name=result["name"],
                                scheduled_time=result.get("scheduled_time"),
                            )
                        )
                except Exception as e:
                    logger.error(f"åˆ›å»ºå¾…åŠå¤±è´¥: {e}", exc_info=True)
                    continue
            logger.info(f"â±ï¸ åˆ›å»ºå¾…åŠåˆ°æ•°æ®åº“: {time.time() - step_start:.3f}s")

        total_time = time.time() - total_start
        logger.info(f"âœ… æ‚¬æµ®çª—æˆªå›¾å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.3f}s (æå– {len(extracted_todos)} ä¸ªå¾…åŠï¼Œåˆ›å»º {created_count} ä¸ª)")
        
        return FloatingCaptureResponse(
            success=True,
            message=f"æˆåŠŸæå– {len(extracted_todos)} ä¸ªå¾…åŠï¼Œåˆ›å»º {created_count} ä¸ª",
            extracted_todos=extracted_todo_models,
            created_todos=created_todos,
            created_count=created_count,
        )

    except Exception as e:
        logger.error(f"å¤„ç†æ‚¬æµ®çª—æˆªå›¾å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¤„ç†æˆªå›¾å¤±è´¥: {str(e)}") from e


def _call_vision_model_with_base64(
    llm_client: LLMClient,
    image_base64: str,
    existing_todos: list[dict[str, Any]],
) -> list[dict[str, Any]]:
    """
    ä½¿ç”¨ base64 å›¾ç‰‡ç›´æ¥è°ƒç”¨è§†è§‰æ¨¡å‹

    Args:
        llm_client: LLM å®¢æˆ·ç«¯
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡
        existing_todos: å·²æœ‰å¾…åŠåˆ—è¡¨

    Returns:
        æå–çš„å¾…åŠåˆ—è¡¨
    """
    try:
        step_start = time.time()
        
        # æ ¼å¼åŒ–å·²æœ‰å¾…åŠåˆ—è¡¨ä¸º JSON
        existing_todos_json = json.dumps(
            [
                {
                    "id": todo.get("id"),
                    "name": todo.get("name"),
                    "description": todo.get("description"),
                }
                for todo in existing_todos[:50]  # é™åˆ¶æ•°é‡
            ],
            ensure_ascii=False,
            indent=2,
        )

        # ä»é…ç½®æ–‡ä»¶åŠ è½½æç¤ºè¯
        system_prompt = get_prompt("auto_todo_detection", "system_assistant")
        user_prompt = get_prompt(
            "auto_todo_detection",
            "user_prompt",
            existing_todos_json=existing_todos_json,
        )

        # æ„å»ºå®Œæ•´çš„æç¤ºè¯
        full_prompt = f"{system_prompt}\n\n{user_prompt}"

        # ç¡®ä¿ base64 æœ‰æ­£ç¡®çš„å‰ç¼€
        if not image_base64.startswith("data:"):
            image_base64 = f"data:image/png;base64,{image_base64}"

        # æ„å»ºæ¶ˆæ¯å†…å®¹
        content = [
            {
                "type": "image_url",
                "image_url": {"url": image_base64},
            },
            {"type": "text", "text": full_prompt},
        ]

        messages = [{"role": "user", "content": content}]
        
        prep_time = time.time() - step_start
        logger.info(f"  â±ï¸ æ„å»ºè¯·æ±‚å‡†å¤‡: {prep_time:.3f}s")

        # è·å–è§†è§‰æ¨¡å‹é…ç½®
        vision_model = settings.llm.vision_model or settings.llm.model
        
        # è®¡ç®—å›¾ç‰‡å¤§å°
        image_size_kb = len(image_base64) * 3 / 4 / 1024  # Base64 è§£ç åå¤§å°ä¼°ç®—
        logger.info(f"ğŸ“· è°ƒç”¨è§†è§‰æ¨¡å‹ {vision_model} (å›¾ç‰‡å¤§å°: {image_size_kb:.1f}KB)")

        # è°ƒç”¨æ¨¡å‹
        api_start = time.time()
        response = llm_client.client.chat.completions.create(
            model=vision_model,
            messages=messages,
            temperature=0.3,
            max_tokens=2000,
            timeout=60,
        )
        api_time = time.time() - api_start
        logger.info(f"  â±ï¸ LLM API è°ƒç”¨è€—æ—¶: {api_time:.3f}s")

        response_text = response.choices[0].message.content or ""
        if not response_text:
            logger.warning("è§†è§‰æ¨¡å‹è¿”å›ç©ºå“åº”")
            return []
        
        logger.info(f"  ğŸ“ LLM å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")

        # è§£æå“åº”
        parse_start = time.time()
        result = _parse_llm_response(response_text)
        logger.info(f"  â±ï¸ è§£æå“åº”: {time.time() - parse_start:.3f}s (æå–åˆ° {len(result)} ä¸ªå¾…åŠ)")
        
        return result

    except Exception as e:
        logger.error(f"è°ƒç”¨è§†è§‰æ¨¡å‹å¤±è´¥: {e}", exc_info=True)
        return []


def _parse_llm_response(response_text: str) -> list[dict[str, Any]]:
    """
    è§£æ LLM å“åº”

    Args:
        response_text: LLM è¿”å›çš„æ–‡æœ¬

    Returns:
        å¾…åŠåˆ—è¡¨
    """
    try:
        # å°è¯•æå– JSON
        json_match = re.search(r"\{.*\}", response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            result = json.loads(json_str)
            # æ”¯æŒ new_todos å’Œ todos ä¸¤ç§æ ¼å¼
            if "new_todos" in result:
                return result["new_todos"]
            if "todos" in result:
                return result["todos"]

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° JSONï¼Œå°è¯•ç›´æ¥è§£æ
        result = json.loads(response_text)
        if "new_todos" in result:
            return result["new_todos"]
        if "todos" in result:
            return result["todos"]

        logger.warning("LLM å“åº”æ ¼å¼ä¸æ­£ç¡®")
        return []

    except json.JSONDecodeError as e:
        logger.error(f"è§£æ LLM å“åº” JSON å¤±è´¥: {e}")
        return []
    except Exception as e:
        logger.error(f"è§£æ LLM å“åº”å¤±è´¥: {e}", exc_info=True)
        return []


def _create_draft_todo(todo_data: dict[str, Any]) -> dict[str, Any] | None:
    """
    åˆ›å»º draft çŠ¶æ€çš„å¾…åŠ

    Args:
        todo_data: å¾…åŠæ•°æ®

    Returns:
        åˆ›å»ºç»“æœæˆ– None
    """
    title = todo_data.get("title", "").strip()
    if not title:
        return None

    description = todo_data.get("description")
    if description:
        description = description.strip()

    source_text = todo_data.get("source_text", "")
    time_info = todo_data.get("time_info", {})
    confidence = todo_data.get("confidence")

    # è®¡ç®— scheduled_time
    scheduled_time = None
    if time_info:
        try:
            reference_time = datetime.now()
            scheduled_time = calculate_scheduled_time(time_info, reference_time)
        except Exception as e:
            logger.warning(f"è®¡ç®— scheduled_time å¤±è´¥: {e}")

    # æ„å»º user_notes
    user_notes_parts = ["æ¥æº: æ‚¬æµ®çª—æˆªå›¾"]
    if source_text:
        user_notes_parts.append(f"æ¥æºæ–‡æœ¬: {source_text}")
    if time_info and time_info.get("raw_text"):
        user_notes_parts.append(f"æ—¶é—´: {time_info.get('raw_text')}")
    if confidence is not None:
        user_notes_parts.append(f"ç½®ä¿¡åº¦: {confidence:.0%}")
    user_notes = "\n".join(user_notes_parts)

    # åˆ›å»ºå¾…åŠ
    todo_id = todo_mgr.create_todo(
        name=title,
        description=description,
        user_notes=user_notes,
        deadline=scheduled_time,
        status="draft",
        priority="none",
        tags=["æ‚¬æµ®çª—æå–"],
    )

    if todo_id:
        logger.info(f"åˆ›å»º draft å¾…åŠ: {todo_id} - {title}")
        return {
            "id": todo_id,
            "name": title,
            "scheduled_time": scheduled_time.isoformat() if scheduled_time else None,
        }

    return None


@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    llm_client = get_llm_client()
    return {
        "status": "ok",
        "llm_available": llm_client.is_available(),
    }
