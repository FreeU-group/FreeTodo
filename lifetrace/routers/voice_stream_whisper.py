"""å®æ—¶è¯­éŸ³è¯†åˆ« WebSocket è·¯ç”± - ä½¿ç”¨ Faster-Whisper è¿›è¡Œæµå¼è¯†åˆ«ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""

import asyncio
import time
from collections import deque
from typing import Any

import numpy as np
from fastapi import APIRouter, WebSocket, WebSocketDisconnect

from lifetrace.util.logging_config import get_logger
from lifetrace.util.settings import settings

logger = get_logger()

# å¸¸é‡å®šä¹‰
MIN_TEXT_LENGTH_FOR_COMMIT = 2  # æäº¤æ–‡æœ¬çš„æœ€å°é•¿åº¦
MIN_AUDIO_DURATION_FOR_SHORT_SENTENCE = 1.0  # çŸ­å¥çš„æœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰
VAD_THRESHOLD_EPSILON = 0.0001  # VADé˜ˆå€¼çš„æœ€å°å€¼
VAD_THRESHOLD_LOW = 0.01  # VADä½é˜ˆå€¼
VAD_THRESHOLD_MEDIUM = 0.05  # VADä¸­ç­‰é˜ˆå€¼
SILENCE_DURATION_THRESHOLD = 0.5  # é™éŸ³æ—¶é•¿é˜ˆå€¼ï¼ˆç§’ï¼‰


def convert_traditional_to_simplified(text: str) -> str:
    """
    å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡

    ä¼˜å…ˆä½¿ç”¨ opencc-python-reimplementedï¼Œå¦‚æœæ²¡æœ‰å®‰è£…åˆ™ä½¿ç”¨ç®€å•æ˜ å°„
    """
    # å°è¯•ä½¿ç”¨ openccï¼ˆå¦‚æœå·²å®‰è£…ï¼‰
    try:
        import opencc

        converter = opencc.OpenCC("t2s")  # ç¹ä½“è½¬ç®€ä½“
        return converter.convert(text)
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£… openccï¼Œä½¿ç”¨ç®€å•æ˜ å°„ï¼ˆå¸¸ç”¨å­—ï¼‰
        traditional_to_simplified = {
            "å­¸": "å­¦",
            "æœƒ": "ä¼š",
            "å¾": "ä»",
            "æ„Ÿ": "æ„Ÿ",
            "å…¨": "å…¨",
            "åœ¨": "åœ¨",
            "å¿ƒ": "å¿ƒ",
            "é ­": "å¤´",
            "çš„": "çš„",
            "æ‚²": "æ‚²",
            "é³´": "é¸£",
            "äºº": "äºº",
            "éœ€": "éœ€",
            "è¦": "è¦",
            "æ„›": "çˆ±",
            "å’Œ": "å’Œ",
            "é—œ": "å…³",
            "çµ": "ç»“",
            "æœ": "æœ",
            "åŸ": "åŸ",
            "å¸‚": "å¸‚",
            "å“ª": "å“ª",
            "æœ‰": "æœ‰",
            "é˜»": "é˜»",
            "ç¤™": "ç¢",
            "åœ": "å›´",
            "éƒ½": "éƒ½",
            "çœ‹": "çœ‹",
            "è‡ª": "è‡ª",
            "å·±": "å·±",
            "æƒ³": "æƒ³",
            "åƒ": "åƒ",
            "èµ°": "èµ°",
            "é": "è¿‡",
            "ç•¶": "å½“",
            "ä½ ": "ä½ ",
            "åš": "åš",
            "äº†": "äº†",
            "äº›": "äº›",
            "ä»€": "ä»€",
            "éº¼": "ä¹ˆ",
            "äº‹": "äº‹",
            "æƒ…": "æƒ…",
            "ä¹Ÿ": "ä¹Ÿ",
            "è¨±": "è®¸",
            "æ˜¯": "æ˜¯",
            "å‚·": "ä¼¤",
            "çµ¦": "ç»™",
            "æˆ‘": "æˆ‘",
            "ä¸€": "ä¸€",
            "å€‹": "ä¸ª",
            "å¤±": "å¤±",
            "èª¤": "è¯¯",
            "çœŸ": "çœŸ",
            "å¯¦": "å®",
            "å£": "å£",
            "å¾‘": "å¾„",
            "èŠ±": "èŠ±",
            "é»": "ç‚¹",
            "æ™‚": "æ—¶",
            "é–“": "é—´",
            "é‚£": "é‚£",
            "ä¸": "ä¸",
            "æ„": "æ„",
            "åŸ": "åŸ",
            "æ›²": "æ›²",
            "è€Œ": "è€Œ",
            "èƒ½": "èƒ½",
            "é‡": "é‡",
            "å”±": "å”±",
            "å€‘": "ä»¬",
            "çµ‚": "ç»ˆ",
            "ç©¶": "ç©¶",
            "å›": "å›",
            "å»": "å»",
            "åˆ¥": "åˆ«",
            "å†": "å†",
            "æ†¶": "å¿†",
            "å¹´": "å¹´",
        }
        result = []
        for char in text:
            result.append(traditional_to_simplified.get(char, char))
        return "".join(result)


router = APIRouter(prefix="/api/voice", tags=["voice-stream"])

# å…¨å±€ Faster-Whisper æ¨¡å‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
_whisper_model: Any = None
_model_loading_lock = asyncio.Lock()
_model_loading_task: asyncio.Task | None = None


def _load_whisper_model_sync():
    """åŒæ­¥åŠ è½½ Whisper æ¨¡å‹ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰"""
    global _whisper_model
    if _whisper_model is not None:
        return _whisper_model

    try:
        from faster_whisper import WhisperModel
    except ImportError:
        error_msg = (
            "Faster-Whisper æœªå®‰è£…ã€‚ç³»ç»ŸéŸ³é¢‘å®æ—¶è¯†åˆ«éœ€è¦ Faster-Whisperã€‚\n"
            "å®‰è£…æ–¹æ³•ï¼š\n"
            "uv pip install faster-whisper\n"
            "æ³¨æ„ï¼šé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆçº¦ 1.5GBï¼‰"
        )
        logger.error(error_msg)
        raise ImportError(error_msg) from None

    try:
        # ä»é…ç½®è¯»å–æ¨¡å‹å¤§å°ï¼ˆé»˜è®¤ä½¿ç”¨ base æ¨¡å‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®ç‡ï¼‰
        model_size = getattr(settings.speech_recognition, "whisper_model_size", "base")
        device = getattr(settings.speech_recognition, "whisper_device", "cpu")
        compute_type = "int8" if device == "cpu" else "float16"  # CPU ä½¿ç”¨ int8ï¼ŒGPU ä½¿ç”¨ float16

        logger.info(
            f"åˆå§‹åŒ– Faster-Whisper æ¨¡å‹: size={model_size}, device={device}, compute_type={compute_type}"
        )

        _whisper_model = WhisperModel(
            model_size,
            device=device,
            compute_type=compute_type,
        )
        logger.info("Faster-Whisper æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    except Exception:
        logger.error("Faster-Whisper æ¨¡å‹åˆå§‹åŒ–å¤±è´¥", exc_info=True)
        raise

    return _whisper_model


async def get_whisper_model():
    """è·å– Faster-Whisper æ¨¡å‹ï¼ˆå¼‚æ­¥ï¼Œæ”¯æŒåå°é¢„åŠ è½½ï¼‰"""
    global _whisper_model, _model_loading_task

    # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œç›´æ¥è¿”å›
    if _whisper_model is not None:
        return _whisper_model

    # å¦‚æœæ­£åœ¨åå°åŠ è½½ï¼Œç­‰å¾…åŠ è½½å®Œæˆ
    if _model_loading_task is not None:
        logger.info("æ¨¡å‹æ­£åœ¨åå°åŠ è½½ï¼Œç­‰å¾…åŠ è½½å®Œæˆ...")
        try:
            await _model_loading_task
            if _whisper_model is not None:
                logger.info("âœ… æ¨¡å‹åå°åŠ è½½å®Œæˆ")
                return _whisper_model
        except Exception as e:
            logger.warning(f"æ¨¡å‹åå°åŠ è½½å¤±è´¥: {e}ï¼Œå°†ç«‹å³åŠ è½½")
            _model_loading_task = None

    # å¦‚æœæ¨¡å‹ä»æœªåŠ è½½ï¼Œç«‹å³åŠ è½½ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼Œé¿å…é˜»å¡ï¼‰
    async with _model_loading_lock:
        # åŒé‡æ£€æŸ¥ï¼ˆå¯èƒ½åœ¨ç­‰å¾…é”æ—¶ï¼Œå…¶ä»–åç¨‹å·²ç»åŠ è½½å®Œæˆï¼‰
        if _whisper_model is not None:
            return _whisper_model

        logger.info("å¼€å§‹åŠ è½½ Faster-Whisper æ¨¡å‹...")
        loop = asyncio.get_event_loop()
        _whisper_model = await loop.run_in_executor(None, _load_whisper_model_sync)
        logger.info("âœ… Faster-Whisper æ¨¡å‹åŠ è½½å®Œæˆ")
        return _whisper_model


async def preload_whisper_model():
    """åå°é¢„åŠ è½½ Whisper æ¨¡å‹ï¼ˆä¸é˜»å¡å¯åŠ¨ï¼‰"""
    global _whisper_model, _model_loading_task

    # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œç›´æ¥è¿”å›
    if _whisper_model is not None:
        logger.info("Whisper æ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡é¢„åŠ è½½")
        return

    # å¦‚æœæ­£åœ¨åŠ è½½ï¼Œç­‰å¾…å®Œæˆ
    if _model_loading_task is not None:
        logger.info("Whisper æ¨¡å‹æ­£åœ¨åå°åŠ è½½ä¸­ï¼Œç­‰å¾…å®Œæˆ...")
        try:
            await _model_loading_task
            logger.info("âœ… Whisper æ¨¡å‹åå°é¢„åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.warning(f"Whisper æ¨¡å‹åå°é¢„åŠ è½½å¤±è´¥: {e}")
        return

    # å¯åŠ¨åå°åŠ è½½ä»»åŠ¡
    async def load_task():
        try:
            await get_whisper_model()
        except Exception as e:
            logger.warning(f"Whisper æ¨¡å‹é¢„åŠ è½½å¤±è´¥: {e}")

    _model_loading_task = asyncio.create_task(load_task())
    logger.info("âœ… å·²å¯åŠ¨ Whisper æ¨¡å‹åå°é¢„åŠ è½½ä»»åŠ¡")


class StreamingPolicy:
    """æµå¼ç­–ç•¥ - æ™ºèƒ½å†³å®šä½•æ—¶æäº¤è¯†åˆ«ç»“æœ"""

    def __init__(
        self,
        min_chunk_duration: float = 0.3,  # æœ€å°å—æ—¶é•¿ï¼ˆç§’ï¼‰
        max_chunk_duration: float = 2.0,  # æœ€å¤§å—æ—¶é•¿ï¼ˆç§’ï¼‰
        silence_threshold: float = 0.5,  # é™éŸ³é˜ˆå€¼ï¼ˆç§’ï¼‰
    ):
        self.min_chunk_duration = min_chunk_duration
        self.max_chunk_duration = max_chunk_duration
        self.silence_threshold = silence_threshold

    def should_commit(
        self, audio_duration: float, has_silence: bool, text_length: int = 0
    ) -> tuple[bool, bool]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æäº¤ç»“æœï¼ˆå‚è€ƒ WhisperLiveKit çš„æ™ºèƒ½ç­–ç•¥ï¼‰

        Returns:
            (should_commit, is_final): æ˜¯å¦æäº¤ï¼Œæ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
        """
        # âš¡ å‚è€ƒ WhisperLiveKitï¼šç­–ç•¥1 - æœ‰æ–‡æœ¬ + æ£€æµ‹åˆ°é™éŸ³ â†’ æäº¤æœ€ç»ˆç»“æœï¼ˆè¯­å¥ç»“æŸï¼‰
        if has_silence and text_length >= MIN_TEXT_LENGTH_FOR_COMMIT:
            return True, True

        # âš¡ å‚è€ƒ WhisperLiveKitï¼šç­–ç•¥2 - çŸ­å¥ï¼ˆ<1ç§’ï¼‰+ æœ‰æ–‡æœ¬ â†’ å¯èƒ½æ˜¯å®Œæ•´çŸ­å¥ï¼Œæäº¤æœ€ç»ˆç»“æœ
        if (
            audio_duration < MIN_AUDIO_DURATION_FOR_SHORT_SENTENCE
            and text_length >= MIN_TEXT_LENGTH_FOR_COMMIT
            and has_silence
        ):
            return True, True

        # âš¡ å‚è€ƒ WhisperLiveKitï¼šç­–ç•¥3 - é•¿å¥ï¼ˆ>0.3ç§’ï¼‰+ æœ‰æ–‡æœ¬ â†’ æäº¤éƒ¨åˆ†ç»“æœï¼ˆå®æ—¶æ›´æ–°ï¼‰
        if audio_duration >= self.min_chunk_duration and text_length >= MIN_TEXT_LENGTH_FOR_COMMIT:
            return True, False

        # âš¡ å‚è€ƒ WhisperLiveKitï¼šç­–ç•¥4 - æ–‡æœ¬å¤ªçŸ­ â†’ ä¸æäº¤ï¼ˆå¯èƒ½æ˜¯å™ªå£°æˆ–æœªå®Œæˆçš„è¯ï¼‰
        if text_length < MIN_TEXT_LENGTH_FOR_COMMIT:
            return False, False

        return False, False


class EventDrivenVAD:
    """äº‹ä»¶é©±åŠ¨çš„ VAD - æ£€æµ‹è¯­éŸ³å¼€å§‹/ç»“æŸäº‹ä»¶"""

    def __init__(self, threshold: float = 0.01, min_silence_duration: float = 0.3):
        self.threshold = threshold
        self.min_silence_duration = min_silence_duration
        self.voice_started = False
        self.silence_duration = 0.0
        self.silence_sample_count = 0
        self.sample_rate = 16000

    def detect(self, pcm_data: bytes) -> str | None:
        """æ£€æµ‹è¯­éŸ³äº‹ä»¶

        Returns:
            "VOICE_STARTED": è¯­éŸ³å¼€å§‹
            "VOICE_ENDED": è¯­éŸ³ç»“æŸ
            None: æ— äº‹ä»¶
        """
        has_voice = self._detect_voice(pcm_data)
        samples = len(pcm_data) // 2
        silence_duration = samples / self.sample_rate

        if has_voice:
            if not self.voice_started:
                self.voice_started = True
                self.silence_duration = 0.0
                return "VOICE_STARTED"
            self.silence_duration = 0.0
        elif self.voice_started:
            self.silence_duration += silence_duration
            if self.silence_duration >= self.min_silence_duration:
                self.voice_started = False
                self.silence_duration = 0.0
                return "VOICE_ENDED"

        return None

    def _detect_voice(self, pcm_data: bytes) -> bool:
        """æ£€æµ‹æ˜¯å¦æœ‰è¯­éŸ³"""
        if len(pcm_data) < 2:
            return False

        audio_int16 = np.frombuffer(pcm_data, dtype=np.int16)
        audio_float = audio_int16.astype(np.float32) / 32768.0
        rms = np.sqrt(np.mean(audio_float**2))
        return rms > self.threshold

    def has_silence(self) -> bool:
        """å½“å‰æ˜¯å¦æœ‰é™éŸ³"""
        return self.silence_duration >= self.min_silence_duration


class PCMAudioProcessor:
    """PCM éŸ³é¢‘æ•°æ®å¤„ç†å™¨ - äº‹ä»¶é©±åŠ¨çš„å®æ—¶è¯†åˆ«

    æ”¯æŒäº‹ä»¶é©±åŠ¨ VAD å’Œæ™ºèƒ½æµå¼ç­–ç•¥
    æ¯300mså¤„ç†ä¸€æ¬¡ï¼Œ100msé‡å ï¼Œæè‡´å®æ—¶æ€§
    """

    def __init__(
        self,
        sample_rate: int = 16000,
        chunk_duration: float = 0.3,  # âš¡ 0.3ç§’å¤„ç†ä¸€æ¬¡ï¼ˆæè‡´å®æ—¶æ€§ï¼‰
        overlap: float = 0.1,  # âš¡ 0.1ç§’é‡å ï¼ˆ100msé‡å ï¼‰
        min_samples: int = 4800,  # âš¡ æœ€å°æ ·æœ¬æ•°ï¼ˆçº¦ 0.3 ç§’ @ 16kHzï¼‰
    ):
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        self.overlap = overlap
        self.min_samples = min_samples

        # ä½¿ç”¨ deque ä½œä¸º PCM æ•°æ®ç¼“å†²åŒºï¼ˆInt16ï¼Œ2 bytes per sampleï¼‰
        max_buffer_samples = int(sample_rate * 10.0)  # æœ€å¤š 10 ç§’
        max_buffer_size = max_buffer_samples * 2  # Int16 = 2 bytes
        self.pcm_buffer = deque(maxlen=max_buffer_size)

        # âš¡ äº‹ä»¶é©±åŠ¨ VAD
        self.vad = EventDrivenVAD(threshold=0.01, min_silence_duration=0.5)

        # âš¡ æµå¼ç­–ç•¥
        self.streaming_policy = StreamingPolicy(
            min_chunk_duration=0.3,
            max_chunk_duration=2.0,
            silence_threshold=0.5,
        )

        # å¤„ç†çŠ¶æ€
        self.is_processing = False
        self.last_process_time = time.time()

        # âš¡ äº‹ä»¶é©±åŠ¨æ ‡å¿—ï¼ˆå‚è€ƒ WhisperLiveKitï¼‰
        self.voice_activity_detected = False  # æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨
        self.voice_ended_detected = False  # æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ

        # âš¡ ç´¯ç§¯éŸ³é¢‘æ—¶é•¿ï¼ˆç”¨äºç²¾ç¡®æ—¶é—´æˆ³è®¡ç®—ï¼‰
        self.total_processed_samples = 0  # ç´¯ç§¯å¤„ç†çš„æ ·æœ¬æ•°ï¼ˆä¸åŒ…æ‹¬é‡å éƒ¨åˆ†ï¼‰

        logger.info(
            f"âš¡ PCM éŸ³é¢‘å¤„ç†å™¨åˆå§‹åŒ–ï¼ˆäº‹ä»¶é©±åŠ¨ï¼‰: chunk={chunk_duration}s, overlap={overlap}s, min_samples={min_samples} (çº¦ {min_samples / sample_rate:.2f}s)"
        )

    def _detect_voice_activity(self, pcm_data: bytes) -> bool:
        """VADæ£€æµ‹ï¼šåˆ¤æ–­PCMæ•°æ®ä¸­æ˜¯å¦æœ‰è¯­éŸ³æ´»åŠ¨

        ä½¿ç”¨ç®€å•çš„RMSï¼ˆRoot Mean Squareï¼‰éŸ³é¢‘ç”µå¹³æ£€æµ‹
        """
        if len(pcm_data) < 2:
            return False

        # å°†PCM Int16è½¬æ¢ä¸ºnumpyæ•°ç»„
        audio_int16 = np.frombuffer(pcm_data, dtype=np.int16)

        # è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼ˆ-1åˆ°1èŒƒå›´ï¼‰
        audio_float = audio_int16.astype(np.float32) / 32768.0

        # è®¡ç®—RMSï¼ˆå‡æ–¹æ ¹ï¼‰
        rms = np.sqrt(np.mean(audio_float**2))

        # å¦‚æœRMSè¶…è¿‡é˜ˆå€¼ï¼Œè®¤ä¸ºæœ‰è¯­éŸ³
        return rms > self.vad_threshold

    def add_pcm_data(self, data: bytes):
        """æ¥æ”¶ PCM æ•°æ®ï¼ˆInt16ï¼‰å¹¶æ·»åŠ åˆ°ç¼“å†²åŒº

        âš¡ å‚è€ƒ WhisperLiveKitï¼šäº‹ä»¶é©±åŠ¨æ¶æ„
        - ç«‹å³æ£€æµ‹ VAD äº‹ä»¶
        - å¦‚æœæœ‰è¯­éŸ³æ´»åŠ¨ï¼Œæ ‡è®°éœ€è¦å¤„ç†
        - ä¸åœ¨è¿™é‡Œå¤„ç†ï¼Œé¿å…é˜»å¡æ•°æ®æ¥æ”¶
        """
        self.pcm_buffer.extend(data)
        current_samples = len(self.pcm_buffer) // 2  # Int16 = 2 bytes per sample

        # âš¡ äº‹ä»¶é©±åŠ¨ VAD æ£€æµ‹ï¼ˆç«‹å³æ£€æµ‹ï¼Œä¸ç­‰å¾…ï¼‰
        vad_event = self.vad.detect(data)
        if vad_event:
            logger.debug(f"ğŸ¤ VAD äº‹ä»¶: {vad_event}, ç¼“å†²åŒº: {current_samples} samples")
            # æ ‡è®°æœ‰è¯­éŸ³æ´»åŠ¨ï¼Œä¸‹æ¬¡ try_process æ—¶ä¼˜å…ˆå¤„ç†
            if vad_event == "VOICE_STARTED":
                self.voice_activity_detected = True
            elif vad_event == "VOICE_ENDED":
                self.voice_ended_detected = True

    async def try_process(self) -> dict | None:
        """å°è¯•å¤„ç†éŸ³é¢‘æ•°æ® - çœŸæ­£çš„äº‹ä»¶é©±åŠ¨å®æ—¶è¯†åˆ«

        âš¡ å‚è€ƒ WhisperLiveKit æ¶æ„ï¼š
        1. ä¼˜å…ˆå“åº” VAD äº‹ä»¶ï¼ˆè¯­éŸ³å¼€å§‹/ç»“æŸï¼‰
        2. æ—¶é—´æ¡ä»¶ä½œä¸ºå…œåº•ï¼ˆç¡®ä¿å®šæœŸå¤„ç†ï¼‰
        3. ç¼“å†²åŒºæº¢å‡ºä¿æŠ¤ï¼ˆå¦‚æœç§¯å‹è¿‡å¤šï¼Œç«‹å³å¤„ç†ï¼‰
        4. é¿å…æ— æ•ˆæ£€æŸ¥ï¼Œæé«˜å®æ—¶æ€§
        """
        current_samples = len(self.pcm_buffer) // 2  # Int16 = 2 bytes per sample
        current_time = time.time()
        time_since_last = current_time - self.last_process_time

        # âš¡ ç¼“å†²åŒºæº¢å‡ºä¿æŠ¤ï¼šå¦‚æœç¼“å†²åŒºè¶…è¿‡ 3 ç§’ï¼Œç«‹å³å¤„ç†ï¼ˆé¿å…ç§¯å‹ï¼‰
        # âš¡ ä¼˜åŒ–ï¼šæé«˜é˜ˆå€¼åˆ°3ç§’ï¼Œå‡å°‘é¢‘ç¹æº¢å‡ºè§¦å‘ï¼ˆå› ä¸ºå¤„ç†é€Ÿåº¦å¯èƒ½è·Ÿä¸ä¸Šï¼‰
        max_buffer_duration = 3.0  # æœ€å¤š 3 ç§’ï¼ˆæé«˜é˜ˆå€¼ï¼Œå‡å°‘é¢‘ç¹è§¦å‘ï¼‰
        max_buffer_samples = int(self.sample_rate * max_buffer_duration)
        buffer_overflow = current_samples > max_buffer_samples

        # âš¡ äº‹ä»¶é©±åŠ¨ä¼˜å…ˆçº§1ï¼šæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ â†’ ç«‹å³å¤„ç†
        voice_ended = self.voice_ended_detected or (
            self.vad.has_silence() and current_samples >= self.min_samples
        )

        # âš¡ äº‹ä»¶é©±åŠ¨ä¼˜å…ˆçº§2ï¼šæ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨ + æœ‰è¶³å¤Ÿæ•°æ® â†’ å¯ä»¥å¤„ç†
        voice_started = self.voice_activity_detected

        # âš¡ æ£€æŸ¥æ˜¯å¦æ»¡è¶³å¤„ç†æ¡ä»¶ï¼ˆäº‹ä»¶ä¼˜å…ˆï¼Œæ—¶é—´å…œåº•ï¼Œæº¢å‡ºä¿æŠ¤ï¼‰
        # æ¡ä»¶1ï¼šæœ‰è¶³å¤Ÿçš„æ•°æ®
        has_enough_data = current_samples >= self.min_samples

        # æ¡ä»¶2ï¼šæ»¡è¶³äº‹ä»¶æˆ–æ—¶é—´æ¡ä»¶æˆ–ç¼“å†²åŒºæº¢å‡º
        event_triggered = voice_ended or (voice_started and time_since_last >= self.chunk_duration)
        time_triggered = time_since_last >= self.chunk_duration

        should_process = has_enough_data and (event_triggered or time_triggered or buffer_overflow)

        if not should_process:
            return None

        # âš¡ é‡ç½®äº‹ä»¶æ ‡å¿—ï¼ˆé¿å…é‡å¤è§¦å‘ï¼‰
        self.voice_activity_detected = False
        self.voice_ended_detected = False

        # âš¡ å¦‚æœç¼“å†²åŒºæº¢å‡ºï¼Œè®°å½•è­¦å‘Š
        if buffer_overflow:
            logger.warning(
                f"âš ï¸ ç¼“å†²åŒºæº¢å‡ºä¿æŠ¤è§¦å‘: {current_samples} samples (çº¦ {current_samples / self.sample_rate:.2f}s) > {max_buffer_samples} samples ({max_buffer_duration}s)ï¼Œç«‹å³å¤„ç†"
            )

        # âš¡ å‚è€ƒ WhisperLiveKitï¼šå¦‚æœæ­£åœ¨å¤„ç†ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ–­ï¼ˆå®ç°çœŸæ­£çš„å®æ—¶ï¼‰
        if self.is_processing:
            # æƒ…å†µ1ï¼šç¼“å†²åŒºæº¢å‡º â†’ å¿…é¡»å¤„ç†ï¼ˆå³ä½¿ä¸Šæ¬¡å¤„ç†æœªå®Œæˆï¼‰
            if buffer_overflow:
                logger.warning("âš ï¸ ç¼“å†²åŒºæº¢å‡ºï¼Œä¸­æ–­ä¸Šæ¬¡å¤„ç†ï¼Œç«‹å³å¤„ç†æ–°æ•°æ®")
                # ä¸è¿”å› Noneï¼Œç»§ç»­å¤„ç†ï¼ˆä½†ä¸Šæ¬¡å¤„ç†çš„ç»“æœå¯èƒ½ä¸¢å¤±ï¼‰
            # æƒ…å†µ2ï¼šä¸Šæ¬¡å¤„ç†å¡ä½ï¼ˆè¶…è¿‡ 2 å€ chunk_durationï¼‰â†’ å…è®¸æ–°å¤„ç†
            elif time_since_last > self.chunk_duration * 2:
                logger.warning(f"ä¸Šæ¬¡å¤„ç†å¯èƒ½å¡ä½ï¼Œå…è®¸æ–°å¤„ç†: time={time_since_last:.2f}s")
            # æƒ…å†µ3ï¼šæ­£å¸¸å¤„ç†ä¸­ â†’ è·³è¿‡ï¼ˆé¿å…å¹¶å‘å¤„ç†ï¼‰
            else:
                logger.debug(f"å·²æœ‰å¤„ç†ä»»åŠ¡åœ¨è¿è¡Œï¼Œè·³è¿‡ï¼ˆtime={time_since_last:.2f}sï¼‰")
                return None

        # âš¡ ç¡®å®šè§¦å‘åŸå› ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        if voice_ended:
            trigger_reason = "VADæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ"
        elif voice_started:
            trigger_reason = "VADæ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨+æ—¶é—´æ¡ä»¶"
        else:
            trigger_reason = "æ—¶é—´æ¡ä»¶ï¼ˆå…œåº•ï¼‰"

        logger.info(
            f"âœ… æ»¡è¶³å¤„ç†æ¡ä»¶ï¼Œå¼€å§‹å¤„ç†: samples={current_samples} (çº¦ {current_samples / self.sample_rate:.2f}s), time={time_since_last:.2f}s, è§¦å‘åŸå› : {trigger_reason}"
        )

        self.is_processing = True
        process_start_time = time.time()

        try:
            # è®°å½•å¤„ç†å¼€å§‹æ—¶çš„ç›¸å¯¹æ—¶é—´ï¼ˆç”¨äºè¿”å›ç²¾ç¡®æ—¶é—´æˆ³ï¼‰
            if not hasattr(self, "recognition_start_time"):
                self.recognition_start_time = process_start_time

            # âš¡ å…³é”®ä¿®å¤ï¼šåªå¤„ç†600msçš„æ•°æ®ï¼Œè€Œä¸æ˜¯æ•´ä¸ªç¼“å†²åŒº
            # 1. è®¡ç®—è¦å¤„ç†çš„æ ·æœ¬æ•°ï¼ˆ600ms = 9600 samplesï¼‰
            target_samples = int(self.sample_rate * self.chunk_duration)  # 600ms = 9600 samples
            current_buffer_samples = len(self.pcm_buffer) // 2

            # å¦‚æœç¼“å†²åŒºæ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å®é™…æ•°æ®é‡ï¼ˆä½†ä¸èƒ½å°äºmin_samplesï¼‰
            if current_buffer_samples < self.min_samples:
                logger.debug(f"ç¼“å†²åŒºæ•°æ®ä¸è¶³: {current_buffer_samples} samples, è·³è¿‡å¤„ç†")
                return None

            # âš¡ åªå¤„ç†300msçš„æ•°æ®ï¼ˆæˆ–å®é™…å¯ç”¨çš„æ•°æ®ï¼Œå–è¾ƒå°å€¼ï¼‰
            process_samples = min(target_samples, current_buffer_samples)
            process_bytes = process_samples * 2  # Int16 = 2 bytes per sample

            # 2. æå–è¦å¤„ç†çš„æ•°æ®ï¼ˆåªæå–300msï¼Œä¸æ˜¯æ•´ä¸ªç¼“å†²åŒºï¼‰
            pcm_bytes = bytes(list(self.pcm_buffer)[:process_bytes])

            # æ£€æŸ¥å­—èŠ‚å¯¹é½ï¼ˆInt16 éœ€è¦ 2 å­—èŠ‚å¯¹é½ï¼‰
            if len(pcm_bytes) % 2 != 0:
                logger.warning(
                    f"PCM æ•°æ®æœªå¯¹é½ï¼Œæˆªæ–­æœ€å 1 å­—èŠ‚: {len(pcm_bytes)} -> {len(pcm_bytes) - 1}"
                )
                pcm_bytes = pcm_bytes[:-1]
                process_bytes = len(pcm_bytes)
                process_samples = process_bytes // 2

            # è®¡ç®—å¤„ç†çš„éŸ³é¢‘æ—¶é•¿ï¼ˆç”¨äºè¿”å›æ—¶é—´æˆ³ï¼‰
            audio_duration = process_samples / self.sample_rate

            # 2. è½¬æ¢ä¸º numpy arrayï¼ˆç›´æ¥å¤„ç† PCM Int16ï¼‰
            logger.debug(
                f"ğŸ” å¼€å§‹è½¬æ¢ PCM åˆ° numpyï¼Œæ ·æœ¬æ•°: {process_samples} (çº¦ {audio_duration:.2f}s)"
            )
            audio_array = self._convert_pcm_to_numpy(pcm_bytes)

            if audio_array is None or len(audio_array) == 0:
                logger.warning(f"âš ï¸ PCM è½¬æ¢å¤±è´¥æˆ–ä¸ºç©ºï¼Œæ ·æœ¬æ•°: {process_samples}")
                return None

            # 3. æ‰§è¡Œè¯­éŸ³è¯†åˆ«ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼Œé¿å…é˜»å¡ï¼‰
            # è®°å½•å¤„ç†å¼€å§‹æ—¶é—´
            process_start_time = time.time()
            audio_duration = len(audio_array) / self.sample_rate
            logger.info(
                f"âœ… PCM è½¬æ¢æˆåŠŸï¼Œå¼€å§‹è¯†åˆ«ï¼ŒéŸ³é¢‘é•¿åº¦: {audio_duration:.2f}s, æ ·æœ¬æ•°: {len(audio_array)}"
            )

            # âš¡ æ·»åŠ è¶…æ—¶æœºåˆ¶ï¼ˆæ ¹æ®éŸ³é¢‘é•¿åº¦åŠ¨æ€è°ƒæ•´ï¼Œæ›´å¿«å“åº”ï¼‰
            # âš¡ ä¼˜åŒ–ï¼šå¯¹äº300msçŸ­éŸ³é¢‘ï¼Œä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æ—¶é—´ï¼ˆ1.0ç§’ï¼‰ï¼Œé¿å…ç­‰å¾…å¤ªä¹…
            # âš¡ å¦‚æœè¯†åˆ«è¶…è¿‡1ç§’è¿˜æ²¡å®Œæˆï¼Œè¯´æ˜å¯èƒ½æœ‰é—®é¢˜ï¼Œç›´æ¥è¶…æ—¶
            timeout_seconds = min(2.0, max(1.0, audio_duration * 2.0 + 0.3))  # 300mséŸ³é¢‘çº¦0.9ç§’è¶…æ—¶
            try:
                result_dict = await asyncio.wait_for(
                    self._transcribe(audio_array, voice_ended), timeout=timeout_seconds
                )
            except TimeoutError:
                logger.error(
                    f"è¯†åˆ«è¶…æ—¶ï¼ˆ>{timeout_seconds:.1f}ç§’ï¼‰ï¼ŒéŸ³é¢‘é•¿åº¦: {audio_duration:.2f}s"
                )
                result_dict = None

            process_duration = time.time() - process_start_time

            # âš¡ å…³é”®ä¿®å¤ï¼šæ— è®ºè¯†åˆ«æˆåŠŸä¸å¦ï¼Œéƒ½è¦æ¸…ç†ç¼“å†²åŒºï¼Œå¦åˆ™ä¼šæ— é™ç§¯ç´¯
            # 4. æ¸…ç†å·²å¤„ç†çš„ç¼“å†²åŒºï¼ˆä¿ç•™100msé‡å ï¼‰
            # âš¡ è®¡ç®—æ—¶é—´æˆ³ï¼ˆä½¿ç”¨ç´¯ç§¯éŸ³é¢‘æ—¶é•¿ï¼Œè€Œä¸æ˜¯å¤„ç†æ—¶é—´ï¼‰
            # æ¯æ¬¡å¤„ç†300msï¼Œä½†åªç´¯ç§¯200msï¼ˆå‡å»100msé‡å ï¼‰
            overlap_samples = int(self.sample_rate * self.overlap)  # 100ms = 1600 samples
            new_samples = process_samples - overlap_samples  # æœ¬æ¬¡æ–°å¢çš„æ ·æœ¬æ•°ï¼ˆ200msï¼‰

            # è®¡ç®—æ—¶é—´æˆ³ï¼šåŸºäºç´¯ç§¯çš„éŸ³é¢‘æ—¶é•¿
            relative_start_time = self.total_processed_samples / self.sample_rate  # ç§’
            relative_end_time = (
                self.total_processed_samples + process_samples
            ) / self.sample_rate  # ç§’

            # æ›´æ–°ç´¯ç§¯æ ·æœ¬æ•°ï¼ˆåªç´¯ç§¯æ–°å¢çš„éƒ¨åˆ†ï¼Œä¸åŒ…æ‹¬é‡å ï¼‰
            self.total_processed_samples += new_samples

            # âš¡ å‚è€ƒ WhisperLiveKitï¼šæ™ºèƒ½æµå¼ç­–ç•¥
            # 1. æ£€æµ‹é™éŸ³çŠ¶æ€
            has_silence = self.vad.has_silence() or voice_ended
            # 2. è·å–è¯†åˆ«æ–‡æœ¬
            text_length = len(result_dict.get("text", "")) if result_dict else 0
            # 3. æ™ºèƒ½å†³ç­–ï¼šæ˜¯å¦æäº¤ä»¥åŠæ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
            should_commit, is_final = self.streaming_policy.should_commit(
                audio_duration=audio_duration,
                has_silence=has_silence,
                text_length=text_length,
            )

            # âš¡ å‚è€ƒ WhisperLiveKitï¼šå¦‚æœæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œå¼ºåˆ¶æ ‡è®°ä¸ºæœ€ç»ˆç»“æœ
            if voice_ended:
                is_final = True
                should_commit = True

            # âš¡ å…³é”®ä¿®å¤ï¼šåªæ¸…ç†å·²å¤„ç†çš„300msæ•°æ®ï¼Œä¿ç•™100msé‡å 
            # å·²å¤„ç†ï¼šprocess_samples (300ms)
            # ä¿ç•™é‡å ï¼šoverlap_samples (100ms)
            # éœ€è¦æ¸…ç†ï¼šprocess_samples - overlap_samples (200ms)
            remove_samples = max(0, process_samples - overlap_samples)  # æ¸…ç†200msï¼Œä¿ç•™100ms
            remove_bytes = remove_samples * 2

            # ä»ç¼“å†²åŒºå¤´éƒ¨ç§»é™¤å·²å¤„ç†çš„æ•°æ®ï¼ˆåªç§»é™¤200msï¼Œä¿ç•™100msé‡å ï¼‰
            removed_count = 0
            for _ in range(min(remove_bytes, len(self.pcm_buffer))):
                if len(self.pcm_buffer) > 0:
                    self.pcm_buffer.popleft()
                    removed_count += 1

            remaining_samples = len(self.pcm_buffer) // 2
            result_text = result_dict.get("text", "") if result_dict else ""

            # âš¡ æ›´æ–° last_process_timeï¼ˆæ— è®ºæ˜¯å¦æˆåŠŸï¼Œéƒ½è¦æ›´æ–°ï¼Œé¿å…å¡ä½ï¼‰
            self.last_process_time = current_time

            if result_dict:
                # âš¡ ä½¿ç”¨æ™ºèƒ½æµå¼ç­–ç•¥çš„ç»“æœ
                final_is_final = is_final if should_commit else result_dict.get("isFinal", False)

                logger.info(
                    f"âœ… å¤„ç†å®Œæˆï¼ˆè€—æ—¶ {process_duration:.3f}sï¼‰ï¼Œè¯†åˆ«: {result_text[:30]}..., æ—¶é—´: {relative_start_time:.2f}s - {relative_end_time:.2f}s, ç­–ç•¥: {'æœ€ç»ˆ' if final_is_final else 'éƒ¨åˆ†'}, æ¸…ç†: {removed_count} bytes ({remove_samples} samples, {remove_samples / self.sample_rate:.2f}s), ä¿ç•™: {remaining_samples} samples ({remaining_samples / self.sample_rate:.2f}s)"
                )

                # âš¡ è¿”å›ç»“æœå’Œæ—¶é—´æˆ³ï¼ˆç”¨äºå‰ç«¯ç²¾ç¡®å›æ”¾ï¼‰
                # âš¡ ç¡®ä¿æ—¶é—´æˆ³æ ¼å¼æ­£ç¡®ï¼šå¿…é¡»æ˜¯æ•°å­—ï¼ˆç§’ï¼‰ï¼Œä¸” endTime >= startTime
                final_start_time = max(0.0, float(relative_start_time))
                final_end_time = max(
                    final_start_time, float(relative_end_time)
                )  # ç¡®ä¿ endTime >= startTime

                return {
                    "text": result_dict.get("text", ""),
                    "isFinal": final_is_final,  # âš¡ ä½¿ç”¨æ™ºèƒ½ç­–ç•¥çš„ç»“æœ
                    "startTime": final_start_time,  # âš¡ ç¡®ä¿æ˜¯æµ®ç‚¹æ•°ï¼ˆç§’ï¼‰
                    "endTime": final_end_time,  # âš¡ ç¡®ä¿æ˜¯æµ®ç‚¹æ•°ï¼ˆç§’ï¼‰
                    "segments": result_dict.get("segments", []),
                }
            else:
                logger.warning(
                    f"âš ï¸ è¯†åˆ«ç»“æœä¸ºç©ºï¼ˆè€—æ—¶ {process_duration:.3f}sï¼‰ï¼Œä½†ä»æ¸…ç†ç¼“å†²åŒº: æ¸…ç† {removed_count} bytes ({remove_samples} samples), ä¿ç•™: {remaining_samples} samples"
                )
                return None

        except Exception as e:
            logger.error(f"éŸ³é¢‘å¤„ç†å¼‚å¸¸: {e}", exc_info=True)
            # âš¡ å³ä½¿å‡ºé”™ï¼Œä¹Ÿè¦æ¸…ç†ç¼“å†²åŒºï¼Œé¿å…ç§¯å‹
            # ä½†åªæ¸…ç†éƒ¨åˆ†æ•°æ®ï¼ˆé¿å…ä¸¢å¤±å¤ªå¤šï¼‰
            try:
                if len(self.pcm_buffer) > 0:
                    # æ¸…ç†è‡³å°‘ 200ms çš„æ•°æ®ï¼ˆä¸æ­£å¸¸å¤„ç†ä¸€è‡´ï¼‰
                    cleanup_samples = int(self.sample_rate * 0.2)  # 200ms
                    cleanup_bytes = cleanup_samples * 2
                    for _ in range(min(cleanup_bytes, len(self.pcm_buffer))):
                        if len(self.pcm_buffer) > 0:
                            self.pcm_buffer.popleft()
                    logger.warning(
                        f"âš ï¸ å¤„ç†å¼‚å¸¸åæ¸…ç†ç¼“å†²åŒº: {len(self.pcm_buffer) // 2} samples å‰©ä½™"
                    )
            except Exception as cleanup_error:
                logger.error(f"æ¸…ç†ç¼“å†²åŒºå¤±è´¥: {cleanup_error}")
            return None
        finally:
            # âš¡ ç¡®ä¿å¤„ç†çŠ¶æ€æ­£ç¡®æ›´æ–°
            self.is_processing = False
            # last_process_time å·²åœ¨ä¸Šé¢æ›´æ–°ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤æ›´æ–°

    def _convert_pcm_to_numpy(self, pcm_bytes: bytes) -> np.ndarray | None:
        """
        å°† PCM Int16 æ•°æ®è½¬æ¢ä¸º numpy arrayï¼ˆFaster-Whisper éœ€è¦ï¼‰
        å…³é”®ç‚¹ï¼š
        1. ç›´æ¥ä½¿ç”¨ np.frombuffer è§£æ Int16
        2. è½¬æ¢ä¸º float32 å¹¶å½’ä¸€åŒ–åˆ° [-1, 1]
        3. æ•°æ®éªŒè¯
        """
        try:
            # æ£€æŸ¥æ•°æ®å¤§å°
            if len(pcm_bytes) < 2:  # è‡³å°‘ 1 ä¸ªæ ·æœ¬ï¼ˆ2 bytesï¼‰
                return None

            # æ£€æŸ¥å­—èŠ‚å¯¹é½ï¼ˆInt16 éœ€è¦ 2 å­—èŠ‚å¯¹é½ï¼‰
            if len(pcm_bytes) % 2 != 0:
                logger.warning(
                    f"PCM æ•°æ®æœªå¯¹é½ï¼Œæˆªæ–­æœ€å 1 å­—èŠ‚: {len(pcm_bytes)} -> {len(pcm_bytes) - 1}"
                )
                pcm_bytes = pcm_bytes[:-1]

            # è½¬æ¢ä¸º Int16 æ•°ç»„
            audio_int16 = np.frombuffer(pcm_bytes, dtype=np.int16)

            if len(audio_int16) == 0:
                logger.error("è½¬æ¢åæ•°ç»„ä¸ºç©º")
                return None

            # è½¬æ¢ä¸º float32 å¹¶å½’ä¸€åŒ–åˆ° [-1.0, 1.0]
            # è¿™æ˜¯ Whisper è¦æ±‚çš„æ ¼å¼
            audio_float32 = audio_int16.astype(np.float32) / 32768.0

            # æ•°æ®éªŒè¯
            if not np.isfinite(audio_float32).all():
                logger.error("éŸ³é¢‘æ•°æ®åŒ…å«æ— æ•ˆå€¼(inf/nan)")
                return None

            # âš¡ å‚è€ƒ WhisperLiveKitï¼šæ™ºèƒ½é™éŸ³æ£€æµ‹ï¼ˆå¤šç‰¹å¾æ£€æµ‹ï¼‰
            # 1. èƒ½é‡æ£€æµ‹
            energy = np.mean(audio_float32**2)
            # 2. å³°å€¼æ£€æµ‹
            peak = np.max(np.abs(audio_float32))
            # 3. è¿‡é›¶ç‡æ£€æµ‹ï¼ˆè¯­éŸ³é€šå¸¸æœ‰è¾ƒé«˜çš„è¿‡é›¶ç‡ï¼‰
            zero_crossings = np.sum(np.diff(np.sign(audio_float32)) != 0)
            zcr = zero_crossings / len(audio_float32) if len(audio_float32) > 0 else 0

            # ç»¼åˆåˆ¤æ–­ï¼šèƒ½é‡ä½ + å³°å€¼ä½ + è¿‡é›¶ç‡ä½ = é™éŸ³
            is_silence = (
                (energy < VAD_THRESHOLD_EPSILON)
                and (peak < VAD_THRESHOLD_LOW)
                and (zcr < VAD_THRESHOLD_MEDIUM)
            )

            logger.info(
                f"âœ… PCM è½¬æ¢æˆåŠŸ: {len(audio_int16)} samples (çº¦ {len(audio_int16) / self.sample_rate:.2f}s), range=[{audio_float32.min():.3f}, {audio_float32.max():.3f}], èƒ½é‡={energy:.6f}, å³°å€¼={peak:.3f}, è¿‡é›¶ç‡={zcr:.3f}, é™éŸ³={'æ˜¯' if is_silence else 'å¦'}"
            )

            # âš¡ å¦‚æœæ˜¯æ˜æ˜¾é™éŸ³ï¼Œè¿”å›Noneï¼Œè·³è¿‡è¯†åˆ«ï¼ˆèŠ‚çœèµ„æºï¼Œå‚è€ƒ WhisperLiveKitï¼‰
            if is_silence:
                logger.debug(
                    f"ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œè·³è¿‡è¯†åˆ«: energy={energy:.6f}, peak={peak:.3f}, zcr={zcr:.3f}"
                )
                return None

            return audio_float32

        except Exception as e:
            logger.error(f"PCM è½¬æ¢å¼‚å¸¸: {e}", exc_info=True)
            return None

    async def _transcribe(self, audio_array: np.ndarray, voice_ended: bool = False) -> dict | None:
        """æ‰§è¡Œè¯­éŸ³è¯†åˆ«ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰"""
        try:
            model = await get_whisper_model()
            audio_duration = len(audio_array) / self.sample_rate

            logger.debug(f"å‡†å¤‡è¯†åˆ«ï¼ŒéŸ³é¢‘é•¿åº¦: {audio_duration:.2f}s, æ ·æœ¬æ•°: {len(audio_array)}")

            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
            loop = asyncio.get_event_loop()

            # ä½¿ç”¨æ›´å¿«çš„å‚æ•°é…ç½®ï¼Œæé«˜å®æ—¶æ€§
            def transcribe_task():
                logger.debug(f"çº¿ç¨‹æ± ä¸­å¼€å§‹è¯†åˆ«ï¼ŒéŸ³é¢‘é•¿åº¦: {audio_duration:.2f}s")
                start_time = time.time()

                try:
                    # âš¡ ä¼˜åŒ–ï¼šå¯¹äº300msçš„çŸ­éŸ³é¢‘ï¼Œé™ä½VADé˜ˆå€¼ï¼Œé¿å…è¿‡æ»¤æ‰æœ‰æ•ˆè¯­éŸ³
                    # 300mséŸ³é¢‘å¤ªçŸ­ï¼Œå¦‚æœVADé˜ˆå€¼å¤ªé«˜ï¼Œå¯èƒ½ä¼šè¯¯åˆ¤ä¸ºé™éŸ³
                    vad_threshold = 0.3 if audio_duration < 0.5 else 0.5  # çŸ­éŸ³é¢‘ä½¿ç”¨æ›´ä½é˜ˆå€¼

                    segments, info = model.transcribe(
                        audio_array,
                        beam_size=1,  # é™ä½ beam_size ä» 5 åˆ° 1ï¼Œæé«˜é€Ÿåº¦
                        language="zh",  # ä¸­æ–‡
                        task="transcribe",
                        vad_filter=True,  # âš¡ å¯ç”¨ VADï¼Œè¿‡æ»¤é™éŸ³éƒ¨åˆ†ï¼Œæé«˜è¯†åˆ«å‡†ç¡®ç‡
                        vad_parameters={
                            "threshold": vad_threshold,  # âš¡ åŠ¨æ€VADé˜ˆå€¼ï¼šçŸ­éŸ³é¢‘ä½¿ç”¨æ›´ä½é˜ˆå€¼
                            "min_speech_duration_ms": 100,  # âš¡ é™ä½æœ€å°è¯­éŸ³æ—¶é•¿ï¼ˆ100msï¼‰ï¼Œé€‚é…300msçŸ­éŸ³é¢‘
                            "max_speech_duration_s": float("inf"),  # æœ€å¤§è¯­éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
                            "min_silence_duration_ms": 200,  # âš¡ é™ä½æœ€å°é™éŸ³æ—¶é•¿ï¼ˆ200msï¼‰ï¼Œæ›´å¿«å“åº”
                        },
                        condition_on_previous_text=False,  # ä¸ä¾èµ–å‰æ–‡ï¼Œæé«˜é€Ÿåº¦
                        # æ·»åŠ æ›´å¤šä¼˜åŒ–å‚æ•°
                        best_of=1,  # åªå°è¯•ä¸€æ¬¡ï¼Œæé«˜é€Ÿåº¦
                        temperature=0.0,  # ä½¿ç”¨è´ªå©ªè§£ç ï¼Œæœ€å¿«
                    )

                    # ç«‹å³è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆé¿å…ç”Ÿæˆå™¨å»¶è¿Ÿï¼‰
                    segments_list = list(segments)
                    transcribe_duration = time.time() - start_time
                    logger.debug(
                        f"è¯†åˆ«å®Œæˆï¼Œè€—æ—¶: {transcribe_duration:.2f}s, ç‰‡æ®µæ•°: {len(segments_list)}"
                    )

                    return segments_list, info
                except Exception as e:
                    logger.error(f"çº¿ç¨‹æ± ä¸­è¯†åˆ«å¼‚å¸¸: {e}", exc_info=True)
                    raise

            segments_list, info = await loop.run_in_executor(None, transcribe_task)

            # âš¡ æ”¯æŒéƒ¨åˆ†ç»“æœï¼šå®æ—¶è¿”å›éƒ¨åˆ†ç»“æœï¼Œæé«˜ç”¨æˆ·ä½“éªŒ
            # ç­–ç•¥ï¼šå¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µä¸”éŸ³é¢‘è¾ƒçŸ­ï¼ˆ<1ç§’ï¼‰ï¼Œå¯èƒ½æ˜¯éƒ¨åˆ†ç»“æœ
            # å¤šä¸ªç‰‡æ®µã€æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸã€æˆ–éŸ³é¢‘è¾ƒé•¿ï¼ˆ>=1ç§’ï¼‰ï¼Œæ ‡è®°ä¸ºæœ€ç»ˆç»“æœ
            audio_duration_seconds = audio_duration
            is_final = (
                len(segments_list) > 1  # å¤šä¸ªç‰‡æ®µ = æœ€ç»ˆç»“æœ
                or voice_ended  # æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ = æœ€ç»ˆç»“æœ
                or audio_duration_seconds >= 1.0  # éŸ³é¢‘è¾ƒé•¿ï¼ˆ>=1ç§’ï¼‰= æœ€ç»ˆç»“æœ
            )

            # æ”¶é›†æ‰€æœ‰ç‰‡æ®µæ–‡æœ¬
            texts = []
            segment_times = []  # è®°å½•æ¯ä¸ªç‰‡æ®µçš„æ—¶é—´èŒƒå›´
            for segment in segments_list:
                text = segment.text.strip()
                if text:
                    texts.append(text)
                    # è®°å½•ç‰‡æ®µæ—¶é—´ï¼ˆç›¸å¯¹äºè¯†åˆ«å¼€å§‹æ—¶é—´ï¼‰
                    segment_times.append(
                        {
                            "start": segment.start,
                            "end": segment.end,
                        }
                    )

            result = " ".join(texts)
            if result:
                # ç¹ç®€è½¬æ¢ï¼ˆå°†ç¹ä½“è½¬ä¸ºç®€ä½“ï¼‰
                result = convert_traditional_to_simplified(result)
                result_type = "æœ€ç»ˆç»“æœ" if is_final else "éƒ¨åˆ†ç»“æœ"
                logger.info(
                    f"âœ… è¯†åˆ«ç»“æœ ({result_type}): {result} (éŸ³é¢‘é•¿åº¦: {audio_duration:.2f}s, ç‰‡æ®µæ•°: {len(segments_list)})"
                )

                # è¿”å›ç»“æœå’Œæ—¶é—´æˆ³ï¼Œä»¥åŠæ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
                return {
                    "text": result,
                    "isFinal": is_final,
                    "segments": segment_times,  # ç‰‡æ®µæ—¶é—´ä¿¡æ¯
                }
            else:
                logger.debug(f"è¯†åˆ«ç»“æœä¸ºç©º (éŸ³é¢‘é•¿åº¦: {audio_duration:.2f}s)")

            return None

        except Exception as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«å¼‚å¸¸: {e}", exc_info=True)
            return ""

    async def flush(self) -> dict | None:
        """å¼ºåˆ¶å¤„ç†å‰©ä½™æ•°æ®"""
        if len(self.pcm_buffer) > 0:
            pcm_bytes = bytes(self.pcm_buffer)
            current_samples = len(pcm_bytes) // 2
            audio_duration = current_samples / self.sample_rate

            logger.debug(f"å¼ºåˆ¶å¤„ç†å‰©ä½™æ•°æ®: {current_samples} samples (çº¦ {audio_duration:.2f}s)")
            audio_array = self._convert_pcm_to_numpy(pcm_bytes)

            if audio_array is not None and len(audio_array) > 0:
                result_dict = await self._transcribe(audio_array, voice_ended=True)
                if result_dict and result_dict.get("text"):
                    # âš¡ ä½¿ç”¨ç´¯ç§¯æ ·æœ¬æ•°è®¡ç®—æ—¶é—´æˆ³ï¼ˆä¸ try_process ä¸€è‡´ï¼‰
                    relative_start_time = self.total_processed_samples / self.sample_rate
                    relative_end_time = (
                        self.total_processed_samples + current_samples
                    ) / self.sample_rate

                    # âš¡ æ›´æ–°ç´¯ç§¯æ ·æœ¬æ•°
                    self.total_processed_samples += current_samples

                    # âš¡ ç¡®ä¿æ—¶é—´æˆ³æ ¼å¼æ­£ç¡®
                    final_start_time = max(0.0, float(relative_start_time))
                    final_end_time = max(final_start_time, float(relative_end_time))

                    return {
                        "text": result_dict.get("text", ""),
                        "isFinal": True,  # flush æ€»æ˜¯è¿”å›æœ€ç»ˆç»“æœ
                        "startTime": final_start_time,
                        "endTime": final_end_time,
                    }
        return None


@router.websocket("/stream")
async def stream_transcription(websocket: WebSocket):
    """
    å®æ—¶è¯­éŸ³è¯†åˆ« WebSocket ç«¯ç‚¹ï¼ˆä½¿ç”¨ Faster-Whisperï¼‰

    æ¥æ”¶éŸ³é¢‘æµï¼ˆPCM Int16 æ ¼å¼ï¼‰ï¼Œä½¿ç”¨ Faster-Whisper è¿›è¡Œå®æ—¶è¯†åˆ«
    è¿”å›è¯†åˆ«ç»“æœï¼ˆJSON æ ¼å¼ï¼‰
    """
    await websocket.accept()
    logger.info("WebSocket è¿æ¥å·²å»ºç«‹ï¼ˆFaster-Whisper ä¼˜åŒ–ç‰ˆï¼‰")

    # è·å– Faster-Whisper æ¨¡å‹
    try:
        await get_whisper_model()
    except ImportError as e:
        error_msg = str(e)
        logger.error(f"Faster-Whisper æœªå®‰è£…: {error_msg}")
        await websocket.send_json(
            {
                "error": "Faster-Whisper æœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œå®æ—¶è¯†åˆ«ã€‚è¯·å®‰è£… Faster-Whisper ä¾èµ–ã€‚",
                "details": error_msg,
            }
        )
        await websocket.close()
        return

    # âš¡ åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨ï¼ˆäº‹ä»¶é©±åŠ¨çš„å®æ—¶è¯†åˆ«ï¼‰
    # æè‡´å®æ—¶ä¼˜åŒ–ï¼šç±»ä¼¼é£ä¹¦/è¾“å…¥æ³•çš„å®æ—¶è¯†åˆ«ä½“éªŒ
    processor = PCMAudioProcessor(
        sample_rate=16000,
        chunk_duration=0.3,  # âš¡ æ¯ 0.3 ç§’å¤„ç†ä¸€æ¬¡ï¼ˆæè‡´å®æ—¶æ€§ï¼Œå»¶è¿Ÿ < 200msï¼‰
        overlap=0.1,  # âš¡ 0.1 ç§’é‡å ï¼ˆ100msé‡å ï¼Œç¡®ä¿ä¸ä¸¢å¤±è¾¹ç•Œå†…å®¹ï¼‰
        min_samples=4800,  # âš¡ æœ€å° 4800 æ ·æœ¬ï¼ˆçº¦ 0.3 ç§’ @ 16kHzï¼Œæè‡´å®æ—¶ï¼‰
    )

    try:
        while True:
            try:
                # æ¥æ”¶éŸ³é¢‘æ•°æ®
                message = await websocket.receive()

                if "bytes" in message:
                    # äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®ï¼ˆPCM Int16ï¼‰
                    audio_data = message["bytes"]
                    processor.add_pcm_data(audio_data)

                    # âš¡ å°è¯•å¤„ç†ï¼ˆå¦‚æœæ»¡è¶³æ¡ä»¶ï¼‰- æè‡´å®æ—¶
                    result = await processor.try_process()

                    if result:
                        # âš¡ ç«‹å³å‘é€è¯†åˆ«ç»“æœï¼ˆæè‡´å®æ—¶ï¼Œæ”¯æŒéƒ¨åˆ†ç»“æœï¼‰
                        # âš¡ ç¡®ä¿æ—¶é—´æˆ³æ ¼å¼æ­£ç¡®ï¼šstartTime å’Œ endTime å¿…é¡»æ˜¯æ•°å­—ï¼ˆç§’ï¼‰
                        start_time = result.get("startTime", 0)
                        end_time = result.get("endTime", 0)

                        # éªŒè¯æ—¶é—´æˆ³æ ¼å¼
                        if not isinstance(start_time, int | float) or not isinstance(
                            end_time, int | float
                        ):
                            logger.warning(
                                f"æ—¶é—´æˆ³æ ¼å¼é”™è¯¯: startTime={start_time}, endTime={end_time}ï¼Œä½¿ç”¨é»˜è®¤å€¼"
                            )
                            start_time = 0
                            end_time = 0

                        # ç¡®ä¿ endTime >= startTime
                        if end_time < start_time:
                            logger.warning(
                                f"æ—¶é—´æˆ³é€»è¾‘é”™è¯¯: endTime ({end_time}) < startTime ({start_time})ï¼Œä¿®æ­£ä¸º startTime"
                            )
                            end_time = start_time

                        await websocket.send_json(
                            {
                                "text": result.get("text", ""),
                                "isFinal": result.get("isFinal", True),  # éƒ¨åˆ†ç»“æœæˆ–æœ€ç»ˆç»“æœ
                                "startTime": float(start_time),  # âš¡ ç¡®ä¿æ˜¯æµ®ç‚¹æ•°ï¼ˆç§’ï¼‰
                                "endTime": float(end_time),  # âš¡ ç¡®ä¿æ˜¯æµ®ç‚¹æ•°ï¼ˆç§’ï¼‰
                                "segments": result.get("segments", []),  # ç‰‡æ®µæ—¶é—´ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                            }
                        )

                elif "text" in message:
                    # æ–‡æœ¬æ¶ˆæ¯ï¼ˆæ§åˆ¶æ¶ˆæ¯ï¼‰
                    text_msg = message["text"]
                    if text_msg == "EOS":  # End of Stream
                        # å¤„ç†å‰©ä½™çš„éŸ³é¢‘
                        final_result = await processor.flush()
                        if final_result:
                            await websocket.send_json(
                                {
                                    "text": final_result.get("text", ""),
                                    "isFinal": True,  # æœ€ç»ˆç»“æœ
                                    "startTime": final_result.get("startTime", 0),
                                    "endTime": final_result.get("endTime", 0),
                                }
                            )
                        break

            except WebSocketDisconnect:
                logger.info("WebSocket è¿æ¥å·²æ–­å¼€")
                break
            except Exception as e:
                logger.error(f"WebSocket å¤„ç†é”™è¯¯: {e}", exc_info=True)
                await websocket.send_json(
                    {
                        "error": f"å¤„ç†é”™è¯¯: {str(e)}",
                    }
                )
                break

    except asyncio.CancelledError:
        logger.info("WebSocket ä»»åŠ¡è¢«å–æ¶ˆ")
    except Exception as e:
        logger.error(f"WebSocket è¿æ¥é”™è¯¯: {e}", exc_info=True)
    finally:
        try:
            # æ¸…ç†èµ„æº
            if websocket.client_state.name != "DISCONNECTED":
                await websocket.close()
        except Exception:
            pass
        logger.info("WebSocket è¿æ¥å·²å…³é—­")
